{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, col, concat_ws, collect_list, lit, log\n",
    "import sys\n",
    "import re\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SentimentAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(article_id=10012655, comment_counter='source1_10012655_0', comment_author='modoglobe', timestamp=1364221200000.0, post_time=None, comment_text=\"I think the program needs some work and probably some very costly oversight to prevent human rights abuses according to this report from the Canadian Labour Congress:'Canada's Temporary Foreign Worker Program is far from being a modelinitiative. Given the experiences of the Canadian labour movement, it isabundantly clear that the program's design permits the exploitation ofmigrant workers. It operates to serve employers' interests with littlemeaningful regard for compliance, monitoring, or enforcement of nationalor subnational labour standards.'www.canadianlabour.ca/sites/default/files/pdfs/model-program-or-mistake-2011-en.pdf\", TotalVotes='0.0', posVotes=None, negVotes=None, vote='none', reactions=None, replies=None, comment_id='33750cc126314c84b4babae99e97b347', parentID=None, threadID=None, streamId='10012655.0', edited='False', isModerator='False', highlightGroups='[]', moderatorEdit=None, descendantsCount=None, threadTimestamp='1377139077069.0', flagCount='0.0', sender_isSelf='False', sender_loginProvider='Site', data_type='comment', is_empty='N', status='published')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"/Users/ting/Documents/CMPT733/Project/SOCC/raw/gnm_comments.csv\"\n",
    "df = spark.read.load(comment,\n",
    "                     format='com.databricks.spark.csv', \n",
    "                     header='true', \n",
    "                     inferSchema='true')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = df.select('article_id','comment_id','timestamp', 'TotalVotes','posVotes','negVotes','comment_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('article_id', 'int'),\n",
       " ('comment_id', 'string'),\n",
       " ('timestamp', 'double'),\n",
       " ('TotalVotes', 'string'),\n",
       " ('posVotes', 'string'),\n",
       " ('negVotes', 'string'),\n",
       " ('comment_text', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[article_id: int, comment_id: string, timestamp: double, TotalVotes: string, posVotes: string, negVotes: float, comment_text: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=True ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "        \n",
    "#     words = [p_stemmer.stem(w) for w in words]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "#     return(words)\n",
    "    return( \" \".join(words ))\n",
    "\n",
    "def string2int(inputstring):\n",
    "    if not inputstring:\n",
    "        return 0.0\n",
    "    return (float(inputstring))\n",
    "\n",
    "udf_review = udf(lambda w: review_to_wordlist(w), StringType())\n",
    "udf_str2int = udf(lambda s: string2int(s), FloatType())\n",
    "# df_sub.withColumn(\"TotalVotes\",udf_str2int(df_sub.TotalVotes)).show()\n",
    "# df_sub.withColumn(\"posVotes\",udf_str2int(df_sub.posVotes)).show()\n",
    "df_sub.withColumn(\"negVotes\",udf_str2int(df_sub.negVotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|article_id|          comment_id|        cleaned_text|\n",
      "+----------+--------------------+--------------------+\n",
      "|  10012655|33750cc126314c84b...|think program nee...|\n",
      "|  10012655|4ce8f60b0ddd442c8...|offshoring revers...|\n",
      "|  10012655|75900e8bd92c45149...|spell exploitatio...|\n",
      "|  10012655|ac49765f024640ae9...|tfws place econom...|\n",
      "|  10012655|c5b63fd3000e43069...|temporary workers...|\n",
      "|  10012655|8817325c040b4974b...|sense playing gam...|\n",
      "|  10012655|88861ede36de4818b...|never reason excu...|\n",
      "|  10012655|ac87455db20f460f8...|tfws place econom...|\n",
      "|  10012655|7444480408c24db69...|tfws work tenets ...|\n",
      "|  10012655|400856b5f4e84ba18...|    like give thumbs|\n",
      "|  10012655|0da3fd203ac14f1eb...|tfws proper place...|\n",
      "|  10012655|82373e13cfa440b7a...|think hd mining t...|\n",
      "|  10012655|022f42de0a5741bba...|thing developing ...|\n",
      "|  10012655|f86888b1aedd4352a...|yep along way fin...|\n",
      "|  10012655|82d38afae57c4ce49...|            wow fool|\n",
      "|  10012655|5bd2bef942d14e77b...|law employers pay...|\n",
      "|  10012655|57677f49b7ed4d54b...|hmmm recall part ...|\n",
      "|  10012655|bb11e527ba8a4a4a8...|political party w...|\n",
      "|  10012655|b226fde6ba6947a69...|instead complaini...|\n",
      "|  10012655|d338d235567a42f28...|someone running b...|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# myDF=df_sub.withColumn(\"topic_word_count\",topicWord(df_sub.comment_text))\n",
    "clean_df = df_sub.select('article_id', 'comment_id', \\\n",
    "                         udf_review(df_sub.comment_text).alias('cleaned_text')) \n",
    "\n",
    "# clean_df.coalesce(1).write.csv('cleaned_comment', header = True)\n",
    "clean_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------+-----+\n",
      "|article_id|          comment_id|         word|count|\n",
      "+----------+--------------------+-------------+-----+\n",
      "|    535381|bca183ec85d04ba9a...|          the|    5|\n",
      "|    535381|bca183ec85d04ba9a...|       police|    4|\n",
      "|    535381|bca183ec85d04ba9a...|           in|    4|\n",
      "|    535381|bca183ec85d04ba9a...|        world|    3|\n",
      "|    535381|bca183ec85d04ba9a...|         best|    3|\n",
      "|    535381|bca183ec85d04ba9a...|       forces|    2|\n",
      "|    535381|bca183ec85d04ba9a...|     canadian|    1|\n",
      "|    535381|bca183ec85d04ba9a...|        force|    1|\n",
      "|    535381|bca183ec85d04ba9a...|         list|    1|\n",
      "|    535381|bca183ec85d04ba9a...|          com|    1|\n",
      "|    535381|bca183ec85d04ba9a...|           it|    1|\n",
      "|    535381|bca183ec85d04ba9a...|         http|    1|\n",
      "|    535381|bca183ec85d04ba9a...|infotainworld|    1|\n",
      "|    535381|bca183ec85d04ba9a...|       indeed|    1|\n",
      "|    535381|bca183ec85d04ba9a...|           of|    1|\n",
      "|    535381|bca183ec85d04ba9a...|           is|    1|\n",
      "|    535381|bca183ec85d04ba9a...|        found|    1|\n",
      "|    543638|3f349e7b7c6b4a73b...|          for|    7|\n",
      "|    543638|3f349e7b7c6b4a73b...|           to|    6|\n",
      "|    543638|3f349e7b7c6b4a73b...|          and|    6|\n",
      "+----------+--------------------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import operator \n",
    "# def word_count(row):\n",
    "#     r_texts = re.sub(r'[^\\w]', ' ', row['cleaned_text'])\n",
    "#     words = r_texts.split(' ')\n",
    "#     for w in words:\n",
    "# #         yield comment_row(w, 1)\n",
    "#         yield comment_row(row['article_id'], row['comment_id'], w, 1)\n",
    "\n",
    "# comment_file = clean_df.select('article_id', 'comment_id', 'cleaned_text')\n",
    "\n",
    "# comment_row = Row('article_id', 'comment_id', 'word', 'count')\n",
    "# # comment_row = Row('word', 'count')\n",
    "# comment_wordcount = comment_file.rdd.flatMap(word_count).toDF()\n",
    "\n",
    "# comment_wordcount.createOrReplaceTempView('comment_wordcount')\n",
    "# comment_wordcounts = spark.sql(\"\"\"\n",
    "#     SELECT article_id, comment_id, word, sum(count) as count\n",
    "#     FROM comment_wordcount\n",
    "#     GROUP BY article_id, comment_id, word\n",
    "#     ORDER BY article_id, count DESC\n",
    "# \"\"\")\n",
    "\n",
    "# comment_wordcounts.show()\n",
    "# # text_file.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----+-----+\n",
      "|article_id|comment_id|word|count|\n",
      "+----------+----------+----+-----+\n",
      "|  33185073|  678094_0| the|  276|\n",
      "|  33413032|  816447_0| the|  243|\n",
      "|  33303579|  529466_0| the|  239|\n",
      "|  33413032|  816447_0|that|  177|\n",
      "|  33413032|  816447_0|  is|  176|\n",
      "|  33185073|  678094_0| and|  168|\n",
      "|  33413032|  816447_0|  of|  161|\n",
      "|  33413032|  816447_0|   a|  155|\n",
      "|  33413032|  816447_0| you|  153|\n",
      "|  33413032|  816447_0|  to|  148|\n",
      "|  33424030|  606482_0| the|  144|\n",
      "|  33185073|  678094_0|  of|  132|\n",
      "|  33123104|  568439_0| the|  124|\n",
      "|  33303579|  529466_0|  to|  124|\n",
      "|  33347006|  784316_0| the|  124|\n",
      "|  33185073|  678094_0|  to|  124|\n",
      "|  20259976|      null| the|  121|\n",
      "|  18297978|  978845_0| the|  119|\n",
      "|  33413032|  816447_0|   i|  117|\n",
      "|  33185073|  678094_0|   a|  110|\n",
      "+----------+----------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comment_wordcounts = spark.sql(\"\"\"\n",
    "#     SELECT article_id, comment_id, word, sum(count) as count\n",
    "#     FROM comment_wordcount\n",
    "#     GROUP BY article_id, comment_id, word\n",
    "#     ORDER BY count DESC\n",
    "# \"\"\")\n",
    "\n",
    "# comment_wordcounts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model - Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "label_data = '/Users/ting/Documents/CMPT733/Project/sentimentAnalysis/kaggle/data/labeledTrainData.tsv'\n",
    "train = pd.read_csv(label_data, header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ting/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_reviews = train[\"review\"].size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "for i in range( 0, num_reviews ):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_train_reviews.append( review_to_wordlist( train[\"review\"][i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000)\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = forest.fit( train_data_features, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 197535: expected 3 fields, saw 25\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10012655</td>\n",
       "      <td>33750cc126314c84b4babae99e97b347</td>\n",
       "      <td>think program needs work probably costly overs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10012655</td>\n",
       "      <td>4ce8f60b0ddd442c8a3ac70c15feb954</td>\n",
       "      <td>offshoring reverse well union busting say good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012655</td>\n",
       "      <td>75900e8bd92c451491729551878a166d</td>\n",
       "      <td>spell exploitation disgusting practice sanctio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10012655</td>\n",
       "      <td>ac49765f024640ae93e0913cdfbb4d48</td>\n",
       "      <td>tfws place economy canadians would leave home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10012655</td>\n",
       "      <td>c5b63fd3000e4306960411384e2999b2</td>\n",
       "      <td>temporary workers get paid tim horton rest com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                        comment_id  \\\n",
       "0    10012655  33750cc126314c84b4babae99e97b347   \n",
       "1    10012655  4ce8f60b0ddd442c8a3ac70c15feb954   \n",
       "2    10012655  75900e8bd92c451491729551878a166d   \n",
       "3    10012655  ac49765f024640ae93e0913cdfbb4d48   \n",
       "4    10012655  c5b63fd3000e4306960411384e2999b2   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  think program needs work probably costly overs...  \n",
       "1  offshoring reverse well union busting say good...  \n",
       "2  spell exploitation disgusting practice sanctio...  \n",
       "3  tfws place economy canadians would leave home ...  \n",
       "4  temporary workers get paid tim horton rest com...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = '/Users/ting/Documents/CMPT733/Project/sentimentAnalysis/cleaned_comment/part-00000-803122b2-81f6-4428-8fc6-41962b3705d0-c000.csv'\n",
    "test = pd.read_csv(test_data,quoting=3,error_bad_lines=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_test_reviews = test[\"cleaned_text\"]\n",
    "test_data_features = vectorizer.transform(clean_test_reviews.values.astype('U'))\n",
    "# test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_features = test_data_features.toarray()\n",
    "predition = forest.predict(test_data_features)\n",
    "\n",
    "predition = np.asarray(predition)\n",
    "test['sentiment'] = predition\n",
    "test.to_csv('comment_w_sentiment_bw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predition = np.asarray(predition)\n",
    "test['sentiment'] = predition\n",
    "test.to_csv('comment_w_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model - Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "label_data = '/Users/ting/Documents/CMPT733/Project/sentimentAnalysis/kaggle/data/labeledTrainData.tsv'\n",
    "train = pd.read_csv(label_data, header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "unlabel_data = '/Users/ting/Documents/CMPT733/Project/sentimentAnalysis/kaggle/data/unlabeledTrainData.tsv'\n",
    "unlabeled_train = pd.read_csv(unlabel_data, header=0, \\\n",
    "                                delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (4,9,10,11,13,14,16,17,18,23,24,25,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10012655</td>\n",
       "      <td>33750cc126314c84b4babae99e97b347</td>\n",
       "      <td>I think the program needs some work and probab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10012655</td>\n",
       "      <td>4ce8f60b0ddd442c8a3ac70c15feb954</td>\n",
       "      <td>This is just 'offshoring' in reverse as well a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012655</td>\n",
       "      <td>75900e8bd92c451491729551878a166d</td>\n",
       "      <td>How do you spell exploitation? This is a disgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10012655</td>\n",
       "      <td>ac49765f024640ae93e0913cdfbb4d48</td>\n",
       "      <td>TFWs have a place in the economy. Most Canadia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10012655</td>\n",
       "      <td>c5b63fd3000e4306960411384e2999b2</td>\n",
       "      <td>Why should temporary workers get paid more?? H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                        comment_id  \\\n",
       "0    10012655  33750cc126314c84b4babae99e97b347   \n",
       "1    10012655  4ce8f60b0ddd442c8a3ac70c15feb954   \n",
       "2    10012655  75900e8bd92c451491729551878a166d   \n",
       "3    10012655  ac49765f024640ae93e0913cdfbb4d48   \n",
       "4    10012655  c5b63fd3000e4306960411384e2999b2   \n",
       "\n",
       "                                        comment_text  \n",
       "0  I think the program needs some work and probab...  \n",
       "1  This is just 'offshoring' in reverse as well a...  \n",
       "2  How do you spell exploitation? This is a disgu...  \n",
       "3  TFWs have a place in the economy. Most Canadia...  \n",
       "4  Why should temporary workers get paid more?? H...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = \"/Users/ting/Documents/CMPT733/Project/SOCC/raw/gnm_comments.csv\"\n",
    "test = pd.read_csv(test_data)\n",
    "test = test[['article_id', 'comment_id','comment_text']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "        \n",
    "#     words = [p_stemmer.stem(w) for w in words]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ting/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.happierabroad.com\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from unlabeled set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.archive.org/details/LovefromaStranger\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:219: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "print(\"Parsing sentences from unlabeled set\")\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-13 09:15:02,271 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2018-04-13 09:15:02,284 : INFO : collecting all words and their counts\n",
      "2018-04-13 09:15:02,286 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-13 09:15:02,335 : INFO : PROGRESS: at sentence #10000, processed 225803 words, keeping 17776 word types\n",
      "2018-04-13 09:15:02,411 : INFO : PROGRESS: at sentence #20000, processed 451892 words, keeping 24948 word types\n",
      "2018-04-13 09:15:02,462 : INFO : PROGRESS: at sentence #30000, processed 671315 words, keeping 30034 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-13 09:15:02,522 : INFO : PROGRESS: at sentence #40000, processed 897815 words, keeping 34348 word types\n",
      "2018-04-13 09:15:02,585 : INFO : PROGRESS: at sentence #50000, processed 1116963 words, keeping 37761 word types\n",
      "2018-04-13 09:15:02,639 : INFO : PROGRESS: at sentence #60000, processed 1338404 words, keeping 40723 word types\n",
      "2018-04-13 09:15:02,695 : INFO : PROGRESS: at sentence #70000, processed 1561580 words, keeping 43333 word types\n",
      "2018-04-13 09:15:02,743 : INFO : PROGRESS: at sentence #80000, processed 1780887 words, keeping 45714 word types\n",
      "2018-04-13 09:15:02,790 : INFO : PROGRESS: at sentence #90000, processed 2004996 words, keeping 48135 word types\n",
      "2018-04-13 09:15:02,843 : INFO : PROGRESS: at sentence #100000, processed 2226966 words, keeping 50207 word types\n",
      "2018-04-13 09:15:02,890 : INFO : PROGRESS: at sentence #110000, processed 2446580 words, keeping 52081 word types\n",
      "2018-04-13 09:15:02,939 : INFO : PROGRESS: at sentence #120000, processed 2668775 words, keeping 54119 word types\n",
      "2018-04-13 09:15:02,983 : INFO : PROGRESS: at sentence #130000, processed 2894303 words, keeping 55847 word types\n",
      "2018-04-13 09:15:03,029 : INFO : PROGRESS: at sentence #140000, processed 3107005 words, keeping 57346 word types\n",
      "2018-04-13 09:15:03,078 : INFO : PROGRESS: at sentence #150000, processed 3332627 words, keeping 59055 word types\n",
      "2018-04-13 09:15:03,124 : INFO : PROGRESS: at sentence #160000, processed 3555315 words, keeping 60617 word types\n",
      "2018-04-13 09:15:03,174 : INFO : PROGRESS: at sentence #170000, processed 3778655 words, keeping 62077 word types\n",
      "2018-04-13 09:15:03,223 : INFO : PROGRESS: at sentence #180000, processed 3999236 words, keeping 63496 word types\n",
      "2018-04-13 09:15:03,273 : INFO : PROGRESS: at sentence #190000, processed 4224449 words, keeping 64794 word types\n",
      "2018-04-13 09:15:03,321 : INFO : PROGRESS: at sentence #200000, processed 4448603 words, keeping 66087 word types\n",
      "2018-04-13 09:15:03,374 : INFO : PROGRESS: at sentence #210000, processed 4669967 words, keeping 67390 word types\n",
      "2018-04-13 09:15:03,428 : INFO : PROGRESS: at sentence #220000, processed 4894968 words, keeping 68697 word types\n",
      "2018-04-13 09:15:03,481 : INFO : PROGRESS: at sentence #230000, processed 5117545 words, keeping 69958 word types\n",
      "2018-04-13 09:15:03,537 : INFO : PROGRESS: at sentence #240000, processed 5345050 words, keeping 71167 word types\n",
      "2018-04-13 09:15:03,586 : INFO : PROGRESS: at sentence #250000, processed 5559165 words, keeping 72351 word types\n",
      "2018-04-13 09:15:03,635 : INFO : PROGRESS: at sentence #260000, processed 5779146 words, keeping 73478 word types\n",
      "2018-04-13 09:15:03,689 : INFO : PROGRESS: at sentence #270000, processed 6000435 words, keeping 74767 word types\n",
      "2018-04-13 09:15:03,737 : INFO : PROGRESS: at sentence #280000, processed 6226314 words, keeping 76369 word types\n",
      "2018-04-13 09:15:03,785 : INFO : PROGRESS: at sentence #290000, processed 6449474 words, keeping 77839 word types\n",
      "2018-04-13 09:15:03,836 : INFO : PROGRESS: at sentence #300000, processed 6674077 words, keeping 79171 word types\n",
      "2018-04-13 09:15:03,889 : INFO : PROGRESS: at sentence #310000, processed 6899391 words, keeping 80480 word types\n",
      "2018-04-13 09:15:03,939 : INFO : PROGRESS: at sentence #320000, processed 7124278 words, keeping 81808 word types\n",
      "2018-04-13 09:15:03,987 : INFO : PROGRESS: at sentence #330000, processed 7346021 words, keeping 83030 word types\n",
      "2018-04-13 09:15:04,043 : INFO : PROGRESS: at sentence #340000, processed 7575533 words, keeping 84280 word types\n",
      "2018-04-13 09:15:04,101 : INFO : PROGRESS: at sentence #350000, processed 7798803 words, keeping 85425 word types\n",
      "2018-04-13 09:15:04,162 : INFO : PROGRESS: at sentence #360000, processed 8019427 words, keeping 86596 word types\n",
      "2018-04-13 09:15:04,225 : INFO : PROGRESS: at sentence #370000, processed 8246619 words, keeping 87708 word types\n",
      "2018-04-13 09:15:04,282 : INFO : PROGRESS: at sentence #380000, processed 8471766 words, keeping 88878 word types\n",
      "2018-04-13 09:15:04,332 : INFO : PROGRESS: at sentence #390000, processed 8701497 words, keeping 89907 word types\n",
      "2018-04-13 09:15:04,378 : INFO : PROGRESS: at sentence #400000, processed 8924446 words, keeping 90916 word types\n",
      "2018-04-13 09:15:04,426 : INFO : PROGRESS: at sentence #410000, processed 9145796 words, keeping 91880 word types\n",
      "2018-04-13 09:15:04,483 : INFO : PROGRESS: at sentence #420000, processed 9366876 words, keeping 92912 word types\n",
      "2018-04-13 09:15:04,539 : INFO : PROGRESS: at sentence #430000, processed 9594413 words, keeping 93932 word types\n",
      "2018-04-13 09:15:04,599 : INFO : PROGRESS: at sentence #440000, processed 9821166 words, keeping 94906 word types\n",
      "2018-04-13 09:15:04,656 : INFO : PROGRESS: at sentence #450000, processed 10044928 words, keeping 96036 word types\n",
      "2018-04-13 09:15:04,713 : INFO : PROGRESS: at sentence #460000, processed 10277688 words, keeping 97088 word types\n",
      "2018-04-13 09:15:04,767 : INFO : PROGRESS: at sentence #470000, processed 10505613 words, keeping 97933 word types\n",
      "2018-04-13 09:15:04,823 : INFO : PROGRESS: at sentence #480000, processed 10725997 words, keeping 98862 word types\n",
      "2018-04-13 09:15:04,864 : INFO : PROGRESS: at sentence #490000, processed 10952741 words, keeping 99871 word types\n",
      "2018-04-13 09:15:04,911 : INFO : PROGRESS: at sentence #500000, processed 11174397 words, keeping 100765 word types\n",
      "2018-04-13 09:15:04,961 : INFO : PROGRESS: at sentence #510000, processed 11399672 words, keeping 101699 word types\n",
      "2018-04-13 09:15:05,024 : INFO : PROGRESS: at sentence #520000, processed 11623020 words, keeping 102598 word types\n",
      "2018-04-13 09:15:05,084 : INFO : PROGRESS: at sentence #530000, processed 11847418 words, keeping 103400 word types\n",
      "2018-04-13 09:15:05,143 : INFO : PROGRESS: at sentence #540000, processed 12072033 words, keeping 104265 word types\n",
      "2018-04-13 09:15:05,200 : INFO : PROGRESS: at sentence #550000, processed 12297571 words, keeping 105133 word types\n",
      "2018-04-13 09:15:05,252 : INFO : PROGRESS: at sentence #560000, processed 12518861 words, keeping 105997 word types\n",
      "2018-04-13 09:15:05,307 : INFO : PROGRESS: at sentence #570000, processed 12747916 words, keeping 106787 word types\n",
      "2018-04-13 09:15:05,353 : INFO : PROGRESS: at sentence #580000, processed 12969412 words, keeping 107665 word types\n",
      "2018-04-13 09:15:05,397 : INFO : PROGRESS: at sentence #590000, processed 13194937 words, keeping 108501 word types\n",
      "2018-04-13 09:15:05,441 : INFO : PROGRESS: at sentence #600000, processed 13417135 words, keeping 109218 word types\n",
      "2018-04-13 09:15:05,483 : INFO : PROGRESS: at sentence #610000, processed 13638158 words, keeping 110092 word types\n",
      "2018-04-13 09:15:05,529 : INFO : PROGRESS: at sentence #620000, processed 13864483 words, keeping 110837 word types\n",
      "2018-04-13 09:15:05,568 : INFO : PROGRESS: at sentence #630000, processed 14088769 words, keeping 111610 word types\n",
      "2018-04-13 09:15:05,611 : INFO : PROGRESS: at sentence #640000, processed 14309552 words, keeping 112416 word types\n",
      "2018-04-13 09:15:05,663 : INFO : PROGRESS: at sentence #650000, processed 14535308 words, keeping 113196 word types\n",
      "2018-04-13 09:15:05,715 : INFO : PROGRESS: at sentence #660000, processed 14758098 words, keeping 113945 word types\n",
      "2018-04-13 09:15:05,768 : INFO : PROGRESS: at sentence #670000, processed 14981482 words, keeping 114643 word types\n",
      "2018-04-13 09:15:05,823 : INFO : PROGRESS: at sentence #680000, processed 15206314 words, keeping 115354 word types\n",
      "2018-04-13 09:15:05,876 : INFO : PROGRESS: at sentence #690000, processed 15428507 words, keeping 116131 word types\n",
      "2018-04-13 09:15:05,924 : INFO : PROGRESS: at sentence #700000, processed 15657213 words, keeping 116943 word types\n",
      "2018-04-13 09:15:05,970 : INFO : PROGRESS: at sentence #710000, processed 15880202 words, keeping 117596 word types\n",
      "2018-04-13 09:15:06,020 : INFO : PROGRESS: at sentence #720000, processed 16105489 words, keeping 118221 word types\n",
      "2018-04-13 09:15:06,065 : INFO : PROGRESS: at sentence #730000, processed 16331870 words, keeping 118954 word types\n",
      "2018-04-13 09:15:06,108 : INFO : PROGRESS: at sentence #740000, processed 16552903 words, keeping 119668 word types\n",
      "2018-04-13 09:15:06,153 : INFO : PROGRESS: at sentence #750000, processed 16771230 words, keeping 120295 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-13 09:15:06,191 : INFO : PROGRESS: at sentence #760000, processed 16990622 words, keeping 120930 word types\n",
      "2018-04-13 09:15:06,243 : INFO : PROGRESS: at sentence #770000, processed 17217759 words, keeping 121703 word types\n",
      "2018-04-13 09:15:06,284 : INFO : PROGRESS: at sentence #780000, processed 17447905 words, keeping 122402 word types\n",
      "2018-04-13 09:15:06,331 : INFO : PROGRESS: at sentence #790000, processed 17674981 words, keeping 123066 word types\n",
      "2018-04-13 09:15:06,360 : INFO : collected 123504 word types from a corpus of 17798082 raw words and 795538 sentences\n",
      "2018-04-13 09:15:06,361 : INFO : Loading a fresh vocabulary\n",
      "2018-04-13 09:15:06,430 : INFO : min_count=40 retains 16490 unique words (13% of original 123504, drops 107014)\n",
      "2018-04-13 09:15:06,431 : INFO : min_count=40 leaves 17238940 word corpus (96% of original 17798082, drops 559142)\n",
      "2018-04-13 09:15:06,478 : INFO : deleting the raw counts dictionary of 123504 items\n",
      "2018-04-13 09:15:06,482 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-04-13 09:15:06,484 : INFO : downsampling leaves estimated 12749658 word corpus (74.0% of prior 17238940)\n",
      "2018-04-13 09:15:06,533 : INFO : estimated required memory for 16490 words and 300 dimensions: 47821000 bytes\n",
      "2018-04-13 09:15:06,534 : INFO : resetting layer weights\n",
      "2018-04-13 09:15:06,737 : INFO : training model with 4 workers on 16490 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-04-13 09:15:07,750 : INFO : EPOCH 1 - PROGRESS: at 6.29% examples, 795578 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-13 09:15:08,753 : INFO : EPOCH 1 - PROGRESS: at 12.63% examples, 797178 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:09,758 : INFO : EPOCH 1 - PROGRESS: at 18.64% examples, 782757 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-13 09:15:10,759 : INFO : EPOCH 1 - PROGRESS: at 25.51% examples, 804792 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-13 09:15:11,762 : INFO : EPOCH 1 - PROGRESS: at 32.18% examples, 811910 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-13 09:15:12,765 : INFO : EPOCH 1 - PROGRESS: at 39.90% examples, 840543 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:13,767 : INFO : EPOCH 1 - PROGRESS: at 47.79% examples, 864237 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:14,773 : INFO : EPOCH 1 - PROGRESS: at 55.22% examples, 874464 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:15,775 : INFO : EPOCH 1 - PROGRESS: at 62.30% examples, 878699 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:16,777 : INFO : EPOCH 1 - PROGRESS: at 68.61% examples, 870932 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:17,777 : INFO : EPOCH 1 - PROGRESS: at 76.05% examples, 878181 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:18,794 : INFO : EPOCH 1 - PROGRESS: at 82.61% examples, 873489 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-13 09:15:19,795 : INFO : EPOCH 1 - PROGRESS: at 90.02% examples, 879392 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:20,803 : INFO : EPOCH 1 - PROGRESS: at 97.73% examples, 886012 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:21,092 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-13 09:15:21,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 09:15:21,101 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 09:15:21,111 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 09:15:21,113 : INFO : EPOCH - 1 : training on 17798082 raw words (12750044 effective words) took 14.4s, 887329 effective words/s\n",
      "2018-04-13 09:15:22,124 : INFO : EPOCH 2 - PROGRESS: at 7.71% examples, 975438 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:23,128 : INFO : EPOCH 2 - PROGRESS: at 15.34% examples, 969306 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:24,153 : INFO : EPOCH 2 - PROGRESS: at 22.59% examples, 943524 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:25,165 : INFO : EPOCH 2 - PROGRESS: at 28.42% examples, 891225 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:26,192 : INFO : EPOCH 2 - PROGRESS: at 34.22% examples, 854302 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-13 09:15:27,236 : INFO : EPOCH 2 - PROGRESS: at 36.62% examples, 758609 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-13 09:15:28,250 : INFO : EPOCH 2 - PROGRESS: at 39.75% examples, 706914 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:29,274 : INFO : EPOCH 2 - PROGRESS: at 44.44% examples, 691879 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:30,284 : INFO : EPOCH 2 - PROGRESS: at 50.05% examples, 694417 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:31,292 : INFO : EPOCH 2 - PROGRESS: at 55.83% examples, 698043 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:32,293 : INFO : EPOCH 2 - PROGRESS: at 60.64% examples, 691133 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-13 09:15:33,297 : INFO : EPOCH 2 - PROGRESS: at 63.90% examples, 668136 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:34,306 : INFO : EPOCH 2 - PROGRESS: at 67.01% examples, 647396 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:35,337 : INFO : EPOCH 2 - PROGRESS: at 70.72% examples, 633716 words/s, in_qsize 8, out_qsize 1\n",
      "2018-04-13 09:15:36,347 : INFO : EPOCH 2 - PROGRESS: at 75.82% examples, 634411 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:37,354 : INFO : EPOCH 2 - PROGRESS: at 81.64% examples, 640862 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:38,354 : INFO : EPOCH 2 - PROGRESS: at 87.85% examples, 649762 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-13 09:15:39,357 : INFO : EPOCH 2 - PROGRESS: at 93.74% examples, 655199 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:40,358 : INFO : EPOCH 2 - PROGRESS: at 99.77% examples, 661287 words/s, in_qsize 4, out_qsize 0\n",
      "2018-04-13 09:15:40,360 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-13 09:15:40,365 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 09:15:40,371 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 09:15:40,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 09:15:40,386 : INFO : EPOCH - 2 : training on 17798082 raw words (12749500 effective words) took 19.3s, 661791 effective words/s\n",
      "2018-04-13 09:15:41,395 : INFO : EPOCH 3 - PROGRESS: at 7.30% examples, 927307 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:42,402 : INFO : EPOCH 3 - PROGRESS: at 15.01% examples, 947261 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:43,406 : INFO : EPOCH 3 - PROGRESS: at 22.65% examples, 951598 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:44,407 : INFO : EPOCH 3 - PROGRESS: at 30.20% examples, 954666 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:45,410 : INFO : EPOCH 3 - PROGRESS: at 38.06% examples, 961782 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:46,413 : INFO : EPOCH 3 - PROGRESS: at 45.55% examples, 960812 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:47,419 : INFO : EPOCH 3 - PROGRESS: at 51.42% examples, 930144 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-13 09:15:48,422 : INFO : EPOCH 3 - PROGRESS: at 56.99% examples, 902942 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:49,427 : INFO : EPOCH 3 - PROGRESS: at 64.50% examples, 909425 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:50,433 : INFO : EPOCH 3 - PROGRESS: at 71.93% examples, 913078 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:51,437 : INFO : EPOCH 3 - PROGRESS: at 77.60% examples, 895412 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:52,439 : INFO : EPOCH 3 - PROGRESS: at 84.17% examples, 890397 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:53,450 : INFO : EPOCH 3 - PROGRESS: at 90.82% examples, 886680 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:54,461 : INFO : EPOCH 3 - PROGRESS: at 98.06% examples, 888538 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:54,710 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-13 09:15:54,713 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 09:15:54,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 09:15:54,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 09:15:54,728 : INFO : EPOCH - 3 : training on 17798082 raw words (12749921 effective words) took 14.3s, 889457 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-13 09:15:55,738 : INFO : EPOCH 4 - PROGRESS: at 7.60% examples, 961765 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:56,742 : INFO : EPOCH 4 - PROGRESS: at 15.17% examples, 958091 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:57,742 : INFO : EPOCH 4 - PROGRESS: at 22.82% examples, 960600 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:58,744 : INFO : EPOCH 4 - PROGRESS: at 30.44% examples, 963134 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:15:59,751 : INFO : EPOCH 4 - PROGRESS: at 37.84% examples, 956327 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:00,751 : INFO : EPOCH 4 - PROGRESS: at 45.29% examples, 955450 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:01,753 : INFO : EPOCH 4 - PROGRESS: at 52.60% examples, 952596 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:02,757 : INFO : EPOCH 4 - PROGRESS: at 59.78% examples, 949224 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:03,758 : INFO : EPOCH 4 - PROGRESS: at 67.23% examples, 949292 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:04,759 : INFO : EPOCH 4 - PROGRESS: at 74.63% examples, 948796 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:05,764 : INFO : EPOCH 4 - PROGRESS: at 82.15% examples, 949222 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:06,769 : INFO : EPOCH 4 - PROGRESS: at 88.46% examples, 937140 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:07,771 : INFO : EPOCH 4 - PROGRESS: at 94.03% examples, 919450 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-13 09:16:08,722 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-13 09:16:08,732 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 09:16:08,733 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 09:16:08,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 09:16:08,736 : INFO : EPOCH - 4 : training on 17798082 raw words (12751658 effective words) took 14.0s, 910734 effective words/s\n",
      "2018-04-13 09:16:09,755 : INFO : EPOCH 5 - PROGRESS: at 6.51% examples, 819692 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-13 09:16:10,763 : INFO : EPOCH 5 - PROGRESS: at 11.38% examples, 715020 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:11,766 : INFO : EPOCH 5 - PROGRESS: at 18.81% examples, 787914 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:12,770 : INFO : EPOCH 5 - PROGRESS: at 26.18% examples, 824222 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:13,773 : INFO : EPOCH 5 - PROGRESS: at 33.77% examples, 850055 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:14,780 : INFO : EPOCH 5 - PROGRESS: at 41.20% examples, 865863 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:15,787 : INFO : EPOCH 5 - PROGRESS: at 48.72% examples, 878998 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:16,788 : INFO : EPOCH 5 - PROGRESS: at 56.21% examples, 888640 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:17,789 : INFO : EPOCH 5 - PROGRESS: at 63.67% examples, 896295 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:18,792 : INFO : EPOCH 5 - PROGRESS: at 71.10% examples, 901553 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:19,795 : INFO : EPOCH 5 - PROGRESS: at 78.55% examples, 905743 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:20,800 : INFO : EPOCH 5 - PROGRESS: at 86.08% examples, 909687 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:21,805 : INFO : EPOCH 5 - PROGRESS: at 93.51% examples, 912487 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-13 09:16:22,666 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-13 09:16:22,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 09:16:22,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 09:16:22,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 09:16:22,689 : INFO : EPOCH - 5 : training on 17798082 raw words (12748246 effective words) took 13.9s, 914114 effective words/s\n",
      "2018-04-13 09:16:22,691 : INFO : training on a 88990410 raw words (63749369 effective words) took 76.0s, 839338 effective words/s\n",
      "2018-04-13 09:16:22,693 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2018-04-13 09:16:22,695 : INFO : not storing attribute vectors_norm\n",
      "2018-04-13 09:16:22,697 : INFO : not storing attribute cum_table\n",
      "2018-04-13 09:16:23,059 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "# model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Words To Paragraphs, Attempt 1: Vector Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ting/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n",
      "Creating average feature vecs for test reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=1qKps7uG6eM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://5ptsalt.files.wordpress.com/2012/06/sycophant_thumb.jpg?w=766&h=560\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/AlternativeRevenueToolsForMetrolinxAndTheBigMove/info\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nytimes.com/2013/08/28/us/family-sues-miami-beach-in-taser-death-by-the-police.html?src=twr\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.washingtonpost.com/blogs/on-faith/wp/2013/09/03/why-atheists-should-respect-believers/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.thehamiltonian.net/2010/11/post-election-reflections-burning.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/commentary/our-schools-need-to-help-boys-become-men/article14184533/comments/#gigyaComments_19c83c8132fe457eae4727ecfcc46880\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.shd.ca/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ccg-gcc.gc.ca/vessel-procurement/Polar-Icebreaker\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.vancouversun.com/business/middle+class+debate+could+morph+into+common+political/9026776/story.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/report-on-business/careers/career-advice/life-at-work/does-your-mom-know-what-you-do-for-a-living/article15180067/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.gen-4.org/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=kGdGQzGoKJc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/life/facts-and-arguments/what-i-learned-at-law-school-the-poor-need-not-apply/article15443887/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.danieldickin.ca/2012/08/six-years-after-adscam-dirty-liberal.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://bcsitecdamnotfeasible.weebly.com/index.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.sciencedaily.com/releases/2013/08/130827091401.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.wd.gc.ca/eng/77_13584.asp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/report-on-business/tables-turned-on-charity-intelligence-as-charitable-status-revoked/article4564354/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://blogs.telegraph.co.uk/news/damianthompson/100252140/pope-francis-shocked-by-gay-adoption-will-time-take-back-its-person-of-the-year-award/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.huffingtonpost.com/2013/12/29/pope-francis-gay-adoption_n_4516304.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ledevoir.com/politique/quebec/396772/charte-des-valeurs-les-mecontents-n-ont-qu-a-plier-bagage-estime-michaud\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=1_b8WXowpSA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.dailymail.co.uk/tvshowbiz/article-2108806/Seth-Rogen-follows-friend-Jonah-Hills-footsteps-piles-pounds-on.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=KUmZp8pR1uc&feature=player_embedded\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.myexemption.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.tbcdsb.on.ca/files/u1/Catholic_MythsRealities.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.telegraph.co.uk/news/worldnews/northamerica/usa/10595021/Edward-Snowden-Did-the-American-whistleblower-act-alone.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://tinyurl.com/mf43ds\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=9WFVhe1Eqb4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/politics/flaherty-challenges-tories-income-splitting-plan/article16825565/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://rbth.ru/news/2014/02/26/russias_military_intervention_in_ukraine_not_possible_-_official_34568.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=8XqmwhLzrHs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.telegraph.co.uk/news/worldnews/europe/russia/10683298/Russias-information-warriors-are-on-the-march-we-must-respond.html?fb\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.globalresearch.ca/there-are-no-neo-nazis-in-the-ukraine-and-the-obama-administration-does-not-support-fascists/5370269\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.forbes.com/sites/dougbandow/2014/03/03/avoid-war-cold-or-hot-with-russia-over-ukraine-finding-a-way-back-from-the-catastrophic-brink/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cnn.com/2014/03/07/opinion/putin-western-hypocrosy/?hpt=bosread\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.economist.com/news/business/21569059-subways-are-spreading-fast-going-underground\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/globe-debate/robo-calls-get-a-grip-were-canadian/article551567/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/Arms_industry#World.27s_largest_arms_exporters\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://itunes.apple.com/ca/album/john-a.-macdonald-boys-on/id664609891\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://itunes.apple.com/ca/album/dear-quebec-single/id448498327\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theundergroundrailroad.ca/oneabolitionist/2014/03/i-will-never-a-letter-from-a-white-christian-at-the-trc.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/John-Boys-Grant-MacDonald/dp/B00DEO0MXY/ref=sr_1_2_title_0_main?s=music&ie=UTF8&qid=1396249414&sr=1-2&keywords=JOHN+A+MACDONALD+GRANT\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://slatestarcodex.com/2013/04/19/i-do-not-understand-rape-culture/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/Poisoning_the_well\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thoughtundermined.com/2012/07/22/a-closer-look-at-federal-revenues-and-expenditures-by-province/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/report-on-business/taxpayers-oblivious-to-the-cost-of-farm-subsidies/article13055078/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://disqus.com/embed/profile/?base=default&disqus_version=b1c4d73e&f=npdigital#%7B%22user%22%3A%7B%22id%22%3A%22100817866%22%7D%2C%22fullscreen%22%3Atrue%7D\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://tinyurl.com/q8v2m3x\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://crooksandliars.com/2014/04/bernie-sanders-exposes-koch-brothers-goals\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/14th_Waffen_Grenadier_Division_of_the_SS_(1st_Ukrainian)\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.reformed-theology.org/html/books/wall_street/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/Cuban_missile_crisis\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://oi60.tinypic.com/24zyxch.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.merriam-webster.com/dictionary/sycophanthttp://www.oxforddictionaries.com/definition/english/sycophanthttp://dictionary.reference.com/browse/sycophanthttp://www.urbandictionary.com/define.php?term=sycophant\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://content.time.com/time/magazine/article/0,9171,2017200,00.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.forbes.com/sites/paulroderickgregory/2014/05/05/putins-human-rights-council-accidentally-posts-real-crimean-election-results-only-15-voted-for-annexation/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://business.financialpost.com/2014/06/02/tim-hudaks-million-jobs-plan-is-easy-to-achieve/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://ca.answers.yahoo.com/question/index?qid=20100613225239AAtcmTb\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://canadalandshow.com/article/source-globe-editorial-board-endorsed-wynne-liberals-was-overruled\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://muckrack.com/topic/David%20Walmsley\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://travel.gc.ca/destinations/egyptDuh.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.forbes.com/sites/larrybell/2013/05/21/the-greening-of-gores-bank-account/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/canada/calgary/alberta-s-oilsands-touted-as-giants-of-canada-s-economy-1.2534972\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.statcan.gc.ca/tables-tableaux/sum-som/l01/cst01/gdps04a-eng.htmhttp://en.wikipedia.org/wiki/Equalization_payments_in_Canada\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.voltairenet.org/IMG/pdf/Sutton_Wall_Street_and_Hitler-5.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.dailymail.co.uk/news/article-1250872/Climategate-U-turn-Astonishment-scientist-centre-global-warming-email-row-admits-data-organised.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://judithcurry.com/2011/02/19/u-s-to-kill-funding-for-the-ipcc/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.iflscience.com/environment/huge-underground-ocean-discovered-towards-earths-core\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://endracebasedlaw.ca/end-race-based-law-petition\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.nationalgeographic.com/news/2013/10/131015-iraq-war-deaths-survey-2013/http://www.theguardian.com/news/datablog/2010/aug/10/afghanistan-civilian-casualties-statistics\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/world/ukraine-fighting-prevents-crash-site-visit-despite-international-deal/article19797952/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=Py8BF0hHPnc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.spiegel.de/international/germany/german-renewable-energy-policy-takes-toll-on-nature-conservation-a-888094.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://youtu.be/NdlPKFuFeV4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.sunnewsnetwork.ca/sunnews/politics/archives/2014/08/20140807-170029.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://lubbockonline.com/news/040797/ten.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://imgur.com/gallery/SqkFY\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://time.com/3105119/robin-williams-dead-patch-adams-remembers/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://users.humboldt.edu/jwpowell/sisyphus.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cpc.ncep.noaa.gov/products/predictions/90day/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://uk.reuters.com/article/2014/04/17/russia-putin-crimea-idUKL6N0N921H20140417\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbsnews.com/news/12-million-americans-misdiagnosed-each-year-study-says/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.huffingtonpost.ca/junaid-jahangir/muslims-against-isis_b_5715563.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://euromaidanpress.com/2014/09/02/the-smoking-gun-russian-column-confirmed-in-krasnodon/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://euromaidanpress.com/2014/09/04/russias-recruiting-for-fighting-in-ukraine-as-told-by-volunteer-its-a-total-mess/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://euromaidanpress.com/2014/09/04/poroshenko-nato-members-will-provide-support-and-weapons/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/Double_negative\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://albertaventure.com/2014/01/future-water-wars-alberta/http://www.cbc.ca/blueprintalberta/ourwater.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.telegraph.co.uk/news/uknews/scottish-independence/11111435/Justice-Secretary-Grayling-tells-Scots-MPs-Get-off-my-lawn.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://m.youtube.com/watch?v=OWXoRSIxyIU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.bloomberg.com/news/2014-09-29/canadians-job-security-rises-to-highest-in-three-years.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/Nineteen_Eighty-Four#Political_geography\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ecfr.eu/content/entry/commentary_confronting_is_lebanons_tenuous_success_amidst_growing_threat319?utm_source=Sailthru&utm_medium=email&utm_term=%2AMideast%20Brief&utm_campaign=2014_The%20Middle%20East%20Daily_10.3.14\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.globalresearch.ca/virologist-its-too-late-ebola-will-kill-5-million/5401341\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.globalresearch.ca/canadas-secret-war-iraq-ten-years-after-shock-and-awe/5326879\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/world/isis-forces-pushed-back-from-kobani-as-airstrikes-have-effect-1.2792161\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.liberal.ca/what-we-stand-for/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=GzFWRPiNXOI\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.bbc.com/news/blogs-news-from-elsewhere-29881559\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/Sudbury_school\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://hotair.com/archives/2014/11/17/what-the-mainstream-media-wont-tell-you-about-global-warming/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.threehundredeight.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thewalrus.ca/true-blue/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ncdc.noaa.gov/sotc/global/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://lit.md/files/nstarikov/rouble_nationalization-the_way_to_russia%27s_freedom.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://hockeyschtick.blogspot.ca/2013/06/climatologist-dr-john-christy-climate.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.scientificamerican.com/article/how-to-determine-the-scientific-consensus-on-global-warming/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theguardian.com/world/2013/aug/19/cia-admits-role-1953-iranian-coup\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thefederalist.com/2014/09/16/10-ways-obama-has-failed-as-president/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.neuroscientistnews.com/research-news/psychopathic-violent-offenders-brains-can-t-understand-punishment\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://tinyurl.com/p5eyftt\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://ynaija.com/horrible-christian-mob-set-man-on-fire-eat-his-flesh-with-bread-viewer-discretion/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=amu-yy5hnFA&feature=share\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.liberal.ca/statement-liberal-party-canada-leader-justin-trudeau-supreme-court-ruling/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=41tYQ18oK40\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://tinyurl.com/nfqjvgk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.snopes.com/politics/medical/mmrdeaths.asp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/Narcissism\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cmaj.ca/content/183/8/E437.full\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://dictionary.reference.com/browse/rule+of+law\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.sciencemag.org/content/346/6206/234.abstract\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.bbc.com/news/uk-england-nottinghamshire-32117815#orb-footer\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.buteykoeducators.org/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.wikipedia.org/wiki/Total_fertility_rate\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://shoebat.com/2015/04/12/hindus-send-this-message-to-christians-we-will-burn-down-your-entire-church-if-you-do-not-leave/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.therebel.media/_a_disgrace_alberta_human_rights\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thechronicleherald.ca/books/79807-dal-grad-students-take-on-world\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/canada/toronto/justin-trudeau-s-foolish-china-remarks-spark-anger-1.2421351\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://oi61.tinypic.com/2jfa848.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/politics/alberta-elections-message-to-ottawa-incumbents-be-careful/article24328232/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.phac-aspc.gc.ca/aids-sida/publication/survreport/2012/dec/index-eng.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.edmontonjournal.com/news/edmonton/Police+officer+guilty+crash+that+killed+senior+judge/11059117/story.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=ESFWmqWux3s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.realclimate.org/index.php/archives/2014/08/ipcc-attribution-statements-redux-a-response-to-judith-curry/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.tradingeconomics.com/canada/government-debt-to-gdp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://gothamist.com/2015/04/07/brooklyn_bridge_love_locks.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nydailynews.com/new-york/brooklyn/city-love-struck-visitors-stop-attaching-locks-brooklyn-bridge-article-1.1807559\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nobelprize.org/nobel_prizes/lists/all/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://metronews.ca/news/vancouver/1365140/b-c-failing-to-meet-greenhouse-emission-targets-federal-government/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.huffingtonpost.com/brynn-tannehill/fighting-back-against-ant_b_5633450.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.worldpolicy.org/journal/fall2013/Russia-surveillance\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.nationalpost.com/full-comment/justin-trudeau-turns-to-u-s-experts-for-lessons-in-u-s-style-politicshttp://www.thestar.com/news/canada/2012/11/12/justin_trudeaus_campaign_looks_to_obamas_team_for_lessons_in_winning.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://frankmag.ca/2015/04/naughty-tory-cabinet-minister-in-sexting-shocker/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.thecoast.ca/halifax/cbc-please-fire-randy-bachman/Content?oid=4729131\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://en.wikipedia.org/wiki/The_Motherland_Calls\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nytimes.com/2015/06/30/upshot/why-gun-control-and-abortion-are-different-from-gay-marriage.html?hp&action=click&pgtype=Homepage&module=second-column-region&region=top-news&WT.nav=top-news&_r=0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.therebel.media/don_t_worry_the_globe_mail_columnist_will_let_you_know_when_something_is_racist\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.netl.doe.gov/publications/proceedings/02/ngt/Quillen.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ndp.ca/news/ndp-reality-check-ndp-still-best-fiscal-managers-liberals-are-worst-finance-canada\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.mainstreetresearch.ca/2015/07/24/conservative-christmas-in-july/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cra-arc.gc.ca/tx/nnrsdnts/ndvdls/nnrs-eng.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/national/no-voting-rights-for-long-term-canadian-expats-appeal-court-rules/article25590714/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://theconcourse.deadspin.com/i-dont-think-david-brooks-is-okay-you-guys-1702674607http://www.salon.com/2015/06/15/the_facts_vs_david_brooks_startling_inaccuracies_raise_questions_about_his_latest_book/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://medical-dictionary.thefreedictionary.com/baby\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://tinyurl.com/pdfh7xk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.pressprogress.ca/6_charts_show_stephen_harper_has_the_worst_economic_record_of_any_prime_minister_since_world_war_ii\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/politics/harper-government-directive-went-to-civil-servants-1.1042268\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.urbandictionary.com/define.php?term=Nixon+of+the+North\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.leadnow.ca/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.huffingtonpost.ca/2015/03/05/wynne-previews-action-pla_n_6813054.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.pressprogress.ca/en/post/another-conservative-law-struck-down-supreme-court-whats-next\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://tinyurl.com/3p7qqby\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.nationalpost.com/news/world/ndp-was-paying-some-punjabi-phone-canvassers-13-four-bucks-less-than-their-english-counterparts\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://historyofbd24.blogspot.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.forbes.com/sites/jacobsullum/2014/07/10/how-is-marijuana-legalization-going-so-far-the-price-of-pot-peace-looks-like-a-bargain/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=caCdjA6-ZNg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.change.org/p/globe-and-mail-include-elizabeth-may-in-the-globe-federal-election-debate?recruiter=34378184&utm_source=share_petition&utm_medium=copylink\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nytimes.com/2015/08/16/opinion/sunday/the-closing-of-the-canadian-mind.html?_r=1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.watershedsentinel.ca/content/harper-evangelical-capitalism\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://ipolitics.ca/2015/08/25/the-eye-roll-a-viral-video-pulls-the-late-jim-flaherty-into-the-duffy-debate/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://reneweconomy.com.au/2015/california-forces-pensions-funds-to-divest-from-coal-but-future-fund-digs-in-63765\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.economist.com/blogs/freeexchange/2013/08/labour-markets-0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.you?tube.com/watch??v=G06b83Zphn8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nationalobserver.com/2015/08/27/news/why-harper-corrupted-senate\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nytimes.com/2015/08/16/opinion/sunday/the-closing-of-the-canadian-mind.html?_r=0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.nationalpost.com/news/world/with-more-syrians-en-route-sweden-struggles-to-maintain-identity-as-country-where-refugees-are-welcome\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=UpZuEmKwNjM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thetyee.ca/Opinion/2013/12/16/Harper-Mandela/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.nationalpost.com/full-comment/how-chretien-is-still-getting-it-wrong\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/canada/migrants-accuse-canadian-officials-of-abuse-1.172065\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/world/dictator-was-lobbied-by-chretien/article4115664/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://globalnews.ca/news/1708990/exclusive-harper-government-quietly-signed-customs-agreement-with-china/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.commondreams.org/news/2015/07/09/big-oil-knew-big-oil-lied-and-planet-earth-got-fried\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.bloomberg.com/graphics/2015-whats-warming-the-world/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://appinsys.com/GlobalWarming/GW_Summary.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/m/touch/news/story/1.2975181\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.economist.com/news/americas/21664208-canadians-see-themselves-global-benefactors-fact-they-have-been-pinching\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.newyorker.com/news/daily-comment/pope-francis-and-the-dirty-war\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://poll.munkdebates.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.huffingtonpost.ca/2015/01/14/canada-sued-investor-state-dispute-ccpa_n_6471460.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.blazingcatfur.ca/2015/10/10/tarek-fatah-exposes-radical-links-of-islamist-who-desecrated-citizenship-ceremony-elxn42/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://pjmedia.com/blog/im-glad-that-i-dont-have-canadian-murder-rates-where-i-live/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://en.wikipedia.org/wiki/Covert_United_States_foreign_regime_change_actions\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.madmoizelle.com/etudiante-filme-harcelement-verbal-117901\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.jihadwatch.org/2015/10/51-of-u-s-muslims-want-sharia-60-of-young-muslims-more-loyal-to-islam-than-to-u-s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.breitbart.com/london/2015/10/15/myth-integration-muslims-europe-getting-radical-time-not-less/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.israelnationalnews.com/News/News.aspx/193969#.ViKCDpuFOpo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://sites.lsa.umich.edu/esplab/wp-content/uploads/sites/168/2015/03/Huang_Immunizing-prejudice2011.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.bloombergview.com/articles/2015-09-02/canada-s-economic-slide-in-five-chartsLies!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.gopetition.com/petitions/negotiate-fair-contracts-to-reflect-albertas-fiscal-situation.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.google.ca/?gws_rd=ssl#q=robert+ghiz+scandals\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/politics/canada-judge-judical-review-robin-camp-1.3311574\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://ottawacitizen.com/news/politics/gst-cuts-made-sense\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=Azf320JDdqU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/aw/d/1493784447/ref=mp_s_a_1_1?qid=1447726473&sr=8-1&pi=SY200_QL40&keywords=samuel+landman&dpPl=1&dpID=51wVb1wX5KL&ref=plSrch#\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cnn.com/2015/11/19/politics/house-democrats-refugee-hearings-obama/index.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.alternet.org/election-2016/six-keys-understanding-isiss-barbarism-apocalyptic-vision-and-desire-end-times-battle\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=5Qf6Sv3A9zs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://research.rem.sfu.ca/papers/gunton/NGP%20Spill%20Risk%20Report.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.eurocanadian.ca/2014/05/canadas-expanding-muslim-population.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.europenews.dk/-Muslim-Inbreeding-Impacts-on-intelligence-sanity-health-and-society-78170.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://lmgtfy.com/?q=BC+carbon+tax+results\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://albertawater.com/groundwater-monitoring-and-mapping\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://en.legion-recrute.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.telegraph.co.uk/news/worldnews/asia/afghanistan/12034865/Latest-pictures-show-Isil-training-camp-in-Afghanistan.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.huffingtonpost.ca/brian-mulroney/brian-mulroney-israel-anti-semitism_b_3255764.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.albertacanada.com/files/albertacanada/AIS-Neil-Kaarsemaker.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://smartcommute.ca/about-us/participating-workplaces/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.politifact.com/truth-o-meter/article/2015/mar/26/ted-cruz-born-canada-eligible-run-president-update/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.wrmea.org/congress-u.s.-aid-to-israel/u.s.-financial-aid-to-israel-figures-facts-and-impact.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://boreal.ca/Canadian/Counterfeit.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cannabis-med.org/studies/study.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=SHhrZgojY1Q\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://boreal.ca/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/radio/thesundayedition/levine-flexhaug-coalition-governments-low-paid-contract-teachers-at-canadian-universities-oliver-sacks-1.3215479/academia-s-dirty-little-secret-1.3215885\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.globalsecurity.org/military/world/gulf/salman.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/politics/canada-election-2015-saudi-arabia-neil-macdonald-1.3251239\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://nationalcollective.com/2013/03/14/editorial-better-together-are-lying-to-you/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.addictinginfo.org/2016/01/09/busted-guess-what-the-bundy-militia-was-doing-while-they-were-not-in-gunfights-with-the-fbi/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://creekside1.blogspot.ca/2014/11/arthur-finkelstein-we-have-to-convince.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.health.gov.on.ca/en/news/bulletin/2015/docs/eagreport_20151214_en.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nytimes.com/1995/05/05/us/danish-study-shows-wine-aiding-longevity.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.medicaldaily.com/7-health-benefits-drinking-alcohol-247552\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://observers.france24.com/en/20160115-photo-madaya-girl-syria-fake\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://dspace.library.uvic.ca:8443/bitstream/handle/1828/853/drysdale_c2005.pdf?sequence=1&isAllowed=y\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/politics/trudeau-enlists-ex-military-officers-ambassadors-to-advise-on-foreign-policy/article22107500/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/beta/news/canada/toronto/metrolinx-keeping-expensive-presto-card-1.1176274\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://m.thestar.com/#/article/yourtoronto/education/2015/10/21/province-gives-2-million-to-unions-to-pay-for-bargaining.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thetyee.ca/Opinion/2015/04/17/Liberate-Bank-of-Canada/http://positivemoney.org/how-money-works/banking-101-video-course/https://www.youtube.com/watch?v=vjY5Y-eQZTw\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://positivemoney.org/faqs/will-cause-hyperinflation/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://positivemoney.org/how-money-works/banking-101-video-course/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://blog.trailofbits.com/2016/02/17/apple-can-comply-with-the-fbi-court-order/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://techcrunch.com/2016/02/18/no-apple-has-not-unlocked-70-iphones-for-law-enforcement/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thelibertarianforum.blogspot.ca/2016/02/the-case-against-fluoridation.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.waterloowatch.com/ffw%20brochure%202%20references.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.independent.co.uk/voices/comment/david-cameron-is-finished-whatever-happens-in-the-eu-referendum-a6886361.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.merriam-webster.com/dictionary/drug\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.telegraph.co.uk/news/politics/7807347/Britain-to-emulate-Canadas-radical-solution-to-tackle-debt.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.estevanmercury.ca/news/business-energy/estevan-s-clean-coal-recognized-1.1729612\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thoughtundermined.com/2012/04/24/equalization-misconceptions/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.salon.com/2016/01/25/5_reasons_ted_cruz_is_even_more_dangerous_than_donald_trump_partner/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.fda.gov/ForConsumers/ConsumerUpdates/ucm349063.htm#2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.esquire.com/news-politics/politics/news/a43010/donald-trump-george-wallace/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theguardian.com/us-news/2015/dec/07/donald-trump-ban-all-muslims-entering-us-san-bernardino-shooting\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cnn.com/2015/11/11/politics/donald-trump-deportation-force-debate-immigration/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.stanford.edu/news/2016/march/terrorism-muslims-inclusion-031716.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=is-wgVzc7qw&feature=youtu.be\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.express.co.uk/news/world/607782/Islamic-State-ISIS-economy-caliphate-Syrian-refugees-Europe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/StandWithUs/videos/10153576861462689/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=iJ82nPfWS_k&ebc=ANyPxKo8jhRXF90JaKFBGfk1Khldt4yEskC42YpoUiG9UbuTUvDzKWR0BL_d9_zEJc507ccfV14_\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.beliefnet.com/columnists/commonwordcommonlord/2014/08/think-muslims-havent-condemned-isis-think-again.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/toronto/ryerson-mens-issues-group-says-student-union-shutting-out-male-voices/article27180128/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cjob.com/2016/04/17/omnitrax-accuses-selinger-of-derailing-sale/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://xkcd.com/386/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.nationalpost.com/full-comment/john-robson-the-welfare-state-is-bust-and-so-are-americans\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.change.org/p/christy-clark-its-time-for-bc-to-raise-the-asset-limits-to-a-level-equal-to-the-rest-of-canada?recruiter=44087175&utm_source=share_petition&utm_medium=copylink?recruiter=44087175&utm_source=petition_show&utm_medium=copylink\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://store.heartland.org/shop/why-scientists-disagree-about-global-warming/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://hot-topic.co.nz/nutted-by-reality/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://climateactionnetwork.ca/2016/03/30/more-than-130-b-c-businesses-call-for-a-stronger-carbon-tax/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.scientificamerican.com/article/exxon-knew-about-climate-change-almost-40-years-ago/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.yahoo.com/news/funding-exxon-koch-brothers-gave-deniers-megaphone-climate-160619367.html?ref=gs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://en.wikipedia.org/wiki/Global_cooling\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://thinkprogress.org/climate/2011/07/29/282584/climate-scienists-debunk-latest-bunk-by-denier-roy-spencer/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.skepticalscience.com/skeptic_Roy_Spencer.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theguardian.com/environment/climate-consensus-97-per-cent/2014/may/06/top-ten-global-warming-skeptic-arguments-debunked\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ippr.org/files/images/media/files/publication/2011/05/Worst%20of%20Both%20Worlds%20Jan2011_1820.pdf?noredirect=1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.thestar.com/opinion/commentary/2016/05/15/sophie-grgoire-trudeau-should-have-help-she-needs-to-fill-her-role-editorial.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://m.mlb.com/video/topic/6479266/v515660383/laatex-odors-slide-spikes-giavotella-at-second\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/politics/sophie-gregoire-trudeau-staff-1.3581071\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.transadvocate.com/clinging-to-a-dangerous-past-dr-paul-mchughs-selective-reading-of-transgender-medical-literature_n_13842.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.lifesitenews.com/news/sexual-predator-jailed-after-claiming-to-be-transgender-in-order-to-assault\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.thebeaverton.com/national/item/2690-entire-ndp-caucus-arrive-in-neck-braces-wheelchairs-to-house-of-commons-after-trudeau-s-assault\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=fcgz1TBs2UE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.wnd.com/2016/05/women-confront-hillary-its-about-rape-stupid/#Hillarycan'twin\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.dailymail.co.uk/news/article-3599214/Bill-Clinton-rape-victim-Juanita-Broaddrick-tells-lasting-trauma-1978-attack-claims-victim-told-there.html#DropoutHillary\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.marketwatch.com/story/monsanto-profit-and-sales-fall-more-than-expected-2016-04-06\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=mlwq9HlTFi0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://images.truthometer.co/24.png\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://youtu.be/AlT3NRQqm-4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://en.wikipedia.org/wiki/John_Tory\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.huffingtonpost.ca/2012/09/06/22-minutes-jean-charest-video_n_1862273.htmlLOL!\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/report-on-business/transportation-watchdog-looking-into-cn-runaway-train-collision/article25781083/http://www.tsb.gc.ca/eng/enquetes-investigations/rail/2015/r15t0173/r15t0173.asp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.telegraph.co.uk/opinion/2016/06/04/bbc-spin-hides-the-great-solar-energy-fiasco/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://science.time.com/2013/07/18/how-the-brain-benefits-from-being-bilingual/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=v6EiYbRTv4M\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.salon.com/2015/04/25/progressives_cant_trust_hillary_clinton_on_cultural_and_economic_issues_the_problems_are_stark_and_decades_long/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.diffen.com/difference/Common_Law_vs_Statutory_Law\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.realcleardefense.com/articles/2015/11/05/the_f-35_vs_the_russian_su-35_and_the_pak_fa_108649.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.dailymail.co.uk/news/article-3646038/Muslim-psychologist-Hanan-Dover-links-gays-thieves-killers.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.irena.org/DocumentDownloads/Publications/IRENA_RE_Jobs_Annual_Review_2016.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.nationalpost.com/news/world/turkeys-answer-to-defiant-pride-parade-in-istanbul-tear-gas-water-cannons-and-rubber-bullets\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://scontent-yyz1-1.xx.fbcdn.net/v/t1.0-9/13423843_1736871013259788_5813286746446397381_n.jpg?oh=b978568ac4f98e26bf5529a542986ef9&oe=57E11ACB\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.independent.co.uk/news/uk/politics/eu-referendum-poll-44-would-be-delighted-if-britain-voted-to-leave-only-28-would-feel-the-same-if-we-a7089036.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/Canadas-Forgotten-Thalidomide-Survivors-367365163450639/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.thestar.com/news/canada/2010/02/22/exreform_party_mps_set_to_collect_oncescorned_pensions.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/report-on-business/economy/ontario-drives-manufacturers-away-with-overpriced-electricity/article14854752/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=C0_1HTmh0f0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.telegraph.co.uk/news/2016/06/24/a-second-scottish-referendum-is-not-inevitable/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://vimeo.com/85914510\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://reason.com/blog/2016/06/13/in-america-muslims-are-more-likely-to-su\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/OfficialBritainFirst/videos/1067402603405000/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.jewsnews.co.il/2015/12/18/isis-terrorists-with-150-european-passports-nabbed/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://pamelageller.com/2016/06/shocking-video-islamic-state-executes.html/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.therebel.media/must_see_nigel_farage_rips_into_brussels_bureaucrats_who_never_had_a_real_job_you_re_not_laughing_now_are_you\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.express.co.uk/news/weird/683874/Russia-and-China-to-become-supreme-world-leaders-after-Brexit-destroys-EU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.carlbernstein.com/magazine_cia_and_media.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.breitbart.com/big-government/2016/07/05/hillary-clinton-committed-perjury-benghazi-committee/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.dailymail.co.uk/news/article-3675285/Seven-ISIS-fighters-boiled-alive-fleeing-battlefield-Iraq.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.bnaibrith.ca/al_quds\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.dailymail.co.uk/debate/article-3678087/STEPHEN-GLOVER-Forgive-poor-taste-really-question-Tony-Blair-s-sanity.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://en.wikipedia.org/wiki/50_Cent_Party\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cbc.ca/news/politics/stephen-harper-accepts-world-statesman-of-the-year-award-1.1258743\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://forward.com/news/344932/watch-black-zionist-slams-pro-palestinian-group-cites-arab-slave-trade/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.trudeaumetre.ca/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=9k6lpJJ8wAk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=4ghccQ58jHo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.huffingtonpost.com/entry/donald-j-drumpf-statement-on-banning-canadian-immigration_us_57937237e4b0b3e2427c4cc5\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://pamelageller.com/2016/07/2nd-munich-arrest-jihadi-ali-sonbolys-afghan-muslim-friend-arrested-planning-munich-shooting-for-a-year.html/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=KfJG66mXJmk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=IawEMxTroBk\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.politifact.com/truth-o-meter/statements/2015/sep/21/carly-fiorina/trumps-four-bankruptcies/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://bedejournal.blogspot.ca/2008/11/brith-of-human-rights-part-one.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.wnd.com/2016/07/hillarys-america-no-2-new-york-times-best-seller/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=Az1JyDJ_iKU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://nocamels.com/2014/01/how-israel-became-a-medical-marijuana-powerhouse/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.therebel.media/results_are_in_canadians_want_final_say_on_any_voting_changes\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://video.vanityfair.com/watch/donald-trump-finest-fibs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.quillandquire.com/review/first-nations-second-thoughts/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.thebeaverton.com/national/item/2852-shirtless-stephen-harper-photobombs-calgary-couple-s-wedding-5-dead\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.nytimes.com/2016/08/04/sports/olympics/katinka-hosszu-rio-swimming-husband-shane-tusup.html?_r=0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.telegraph.co.uk/news/2016/07/20/fighters-from-us-backed-moderate-syrian-rebel-group-filmed-cutti/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.therebel.media/breaking_thwarted_major_terrorist_attack_in_canadian_city\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.formsofaddress.info/Names.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=QlvWXtDNnG4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.alternet.org/election-2016/cornel-west-trump-will-be-neofascist-catastrophe-and-clinton-neoliberal-disasterABCD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://iconicphotos.wordpress.com/2009/08/15/robert-stanfield-fumbles/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.theguardian.com/environment/true-north/2016/may/12/the-arsonists-of-fort-mcmurray-have-a-name\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.change.org/p/the-electoral-requesting-the-resignation-of-kathleen-wynne-as-ontario-premier\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://youtu.be/OrXzn0NOu4A\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=aM7FmKnZnCE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://physics.info/music/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://globalnews.ca/news/2185359/toronto-man-denied-subsidized-housing-for-not-being-muslim/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://youtu.be/_rYPp4ofXAs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.alternet.org/election-2016/twitter-destroys-matt-lauer-his-moderating-nbcs-commander-chief-forum\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/StandWithUs/videos/10153977936617689/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://bit.ly/1Xbpc5T\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/gaysfightingislam/?ref=aymt_homepage_panel\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.torontosun.com/2016/07/01/syrian-students-harassing-women-students-in-fredericton-high-school\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.therebel.media/syrian_bullies_investigation\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://youtu.be/C5sosSHLt_c\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.tpsgc-pwgsc.gc.ca/examendepostescanada-canadapostreview/rapport-report/consult-eng.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://immigrationwatchcanada.org/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.washingtontimes.com/news/2016/sep/16/clinton-08-campaign-manager-admits-birther-connect/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://washingtonmonthly.com/2016/09/18/again-with-the-sid-blumenthal-conspiracies/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.newsmax.com/Politics/poll-trump-gains-african-american/2016/09/18/id/748860/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.msn.com/en-ca/money/news/20-countries-drowning-in-debt/ss-BBwoIlW?li=AAggNb9&ocid=UE07DHP\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.politicususa.com/2016/07/21/donald-told-21-fact-checked-proven-lies-acceptance-speech.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.timeshighereducation.com/world-university-rankings/2017/world-ranking#!/page/0/length/25/sort_by/rank_label/sort_order/asc/cols/rank_only\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/TheAmericanDogParty/videos/1800513796851626/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.theguardian.com/global-development/2013/apr/23/china-welfare-system-inflexible-unfair\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://boreal.ca/STM/supremecourt.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://polarbearscience.com/2015/11/18/iucn-red-list-says-global-polar-bear-population-is-22000-31000-26000/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.washingtonpost.com/news/powerpost/paloma/daily-202/2016/09/27/daily-202-why-even-republicans-think-clinton-won-the-first-debate/57e9b033e9b69b3019a1e037/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.democracynow.org/2016/9/19/two_party_tyranny_ralph_nader_on\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=BhvNtczcLfo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/gaysfightingislam/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=RM240RCo1TA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.realclearpolitics.com/epolls/latest_polls/elections/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/emariee.macelheren?fref=nf&pnref=story\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://youtu.be/jUDTcxIqqM0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.zerohedge.com/news/2016-08-26/why-theres-media-blackout-native-american-oil-pipeline-blockade\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.zerohedge.com/news/2016-10-17/caught-tape-clinton-funded-democrat-operatives-inciting-anarchy-trump-rallies\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cracked.com/blog/6-reasons-trumps-rise-that-no-one-talks-about/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.npr.org/2016/01/05/462017461/guns-in-america-by-the-numbers\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://wikileaks.org/podesta-emails/emailid/7452#efmAAAAAv\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.washingtontimes.com/news/2016/jun/3/susan-sarandon-says-hillary-clinton-more-dangerous/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://stephanie-carvin.squarespace.com/academic-cv/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://twitter.com/billygee12/status/793276827619897345/photo/1?ref_src=twsrc%5Etfw\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://en.wikipedia.org/wiki/Bill_Clinton_sexual_misconduct_allegations\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://spectator.org/65921_donald-and-intellectual-snobs/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.washingtonpost.com/posteverything/wp/2016/11/09/trump-won-because-college-educated-americans-are-out-of-touch/?tid=pm_opinions_pop_b\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://theintercept.com/2016/11/09/democrats-trump-and-the-ongoing-dangerous-refusal-to-learn-the-lesson-of-brexit/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.washingtonpost.com/news/morning-mix/wp/2016/11/11/video-shows-group-beating-man-in-chicago-yelling-you-voted-trump-and-dont-vote-trump/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.businesslive.co.za/bd/opinion/2016-11-15-brexit-and-trump-win-show-media-can-no-longer-sway-votes/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://globalnews.ca/news/3068103/the-simpsons-responds-to-its-prediction-of-donald-trump-presidency/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.cnn.com/2016/09/20/politics/george-hw-bush-hillary-clinton/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.ubcaccountable.com/steven-galloway/steven-galloway-apology/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/national/galloway-says-he-regrets-conduct-in-first-statement-since-ubc-firing/article33004493/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=VwcKwGS7OSQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/pages/My-Vote-is-Too-Precious-2-Waste-on-U/343627909070647\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.theglobeandmail.com/news/politics/statscan-to-abandon-no-layoff-policy-as-budget-cuts-loom/article543773/#dashboard/follows/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.thestar.com/news/federal-election/2015/10/19/national-post-comment-editor-resigns-over-election-endorsement.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=bi2QKY3zW8Q\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://news.nationalpost.com/news/canada/canadian-politics/auditor-general-says-canada-revenue-agency-takes-too-long-to-respond-to-tax-complaints-and-its-costing-us\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.freerepublic.com/focus/f-news/3499751/posts\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.frontpagemag.com/fpm/264963/fidel-castro-life-death-monster-discover-networks\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=nfgEvgVC6Qs&app=desktop\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://issuu.com/hydroquebec/docs/comp_2016_en?e=1151578/39216309\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.foreignpolicyjournal.com/2016/01/06/new-hillary-emails-reveal-true-motive-for-libya-intervention\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.youtube.com/watch?v=ZhxR5rt2sOc&t=685s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.wnd.com/files/2013/05/toon130516.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 663173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 663173\n",
      "Review 2000 of 663173\n",
      "Review 3000 of 663173\n",
      "Review 4000 of 663173\n",
      "Review 5000 of 663173\n",
      "Review 6000 of 663173\n",
      "Review 7000 of 663173\n",
      "Review 8000 of 663173\n",
      "Review 9000 of 663173\n",
      "Review 10000 of 663173\n",
      "Review 11000 of 663173\n",
      "Review 12000 of 663173\n",
      "Review 13000 of 663173\n",
      "Review 14000 of 663173\n",
      "Review 15000 of 663173\n",
      "Review 16000 of 663173\n",
      "Review 17000 of 663173\n",
      "Review 18000 of 663173\n",
      "Review 19000 of 663173\n",
      "Review 20000 of 663173\n",
      "Review 21000 of 663173\n",
      "Review 22000 of 663173\n",
      "Review 23000 of 663173\n",
      "Review 24000 of 663173\n",
      "Review 25000 of 663173\n",
      "Review 26000 of 663173\n",
      "Review 27000 of 663173\n",
      "Review 28000 of 663173\n",
      "Review 29000 of 663173\n",
      "Review 30000 of 663173\n",
      "Review 31000 of 663173\n",
      "Review 32000 of 663173\n",
      "Review 33000 of 663173\n",
      "Review 34000 of 663173\n",
      "Review 35000 of 663173\n",
      "Review 36000 of 663173\n",
      "Review 37000 of 663173\n",
      "Review 38000 of 663173\n",
      "Review 39000 of 663173\n",
      "Review 40000 of 663173\n",
      "Review 41000 of 663173\n",
      "Review 42000 of 663173\n",
      "Review 43000 of 663173\n",
      "Review 44000 of 663173\n",
      "Review 45000 of 663173\n",
      "Review 46000 of 663173\n",
      "Review 47000 of 663173\n",
      "Review 48000 of 663173\n",
      "Review 49000 of 663173\n",
      "Review 50000 of 663173\n",
      "Review 51000 of 663173\n",
      "Review 52000 of 663173\n",
      "Review 53000 of 663173\n",
      "Review 54000 of 663173\n",
      "Review 55000 of 663173\n",
      "Review 56000 of 663173\n",
      "Review 57000 of 663173\n",
      "Review 58000 of 663173\n",
      "Review 59000 of 663173\n",
      "Review 60000 of 663173\n",
      "Review 61000 of 663173\n",
      "Review 62000 of 663173\n",
      "Review 63000 of 663173\n",
      "Review 64000 of 663173\n",
      "Review 65000 of 663173\n",
      "Review 66000 of 663173\n",
      "Review 67000 of 663173\n",
      "Review 68000 of 663173\n",
      "Review 69000 of 663173\n",
      "Review 70000 of 663173\n",
      "Review 71000 of 663173\n",
      "Review 72000 of 663173\n",
      "Review 73000 of 663173\n",
      "Review 74000 of 663173\n",
      "Review 75000 of 663173\n",
      "Review 76000 of 663173\n",
      "Review 77000 of 663173\n",
      "Review 78000 of 663173\n",
      "Review 79000 of 663173\n",
      "Review 80000 of 663173\n",
      "Review 81000 of 663173\n",
      "Review 82000 of 663173\n",
      "Review 83000 of 663173\n",
      "Review 84000 of 663173\n",
      "Review 85000 of 663173\n",
      "Review 86000 of 663173\n",
      "Review 87000 of 663173\n",
      "Review 88000 of 663173\n",
      "Review 89000 of 663173\n",
      "Review 90000 of 663173\n",
      "Review 91000 of 663173\n",
      "Review 92000 of 663173\n",
      "Review 93000 of 663173\n",
      "Review 94000 of 663173\n",
      "Review 95000 of 663173\n",
      "Review 96000 of 663173\n",
      "Review 97000 of 663173\n",
      "Review 98000 of 663173\n",
      "Review 99000 of 663173\n",
      "Review 100000 of 663173\n",
      "Review 101000 of 663173\n",
      "Review 102000 of 663173\n",
      "Review 103000 of 663173\n",
      "Review 104000 of 663173\n",
      "Review 105000 of 663173\n",
      "Review 106000 of 663173\n",
      "Review 107000 of 663173\n",
      "Review 108000 of 663173\n",
      "Review 109000 of 663173\n",
      "Review 110000 of 663173\n",
      "Review 111000 of 663173\n",
      "Review 112000 of 663173\n",
      "Review 113000 of 663173\n",
      "Review 114000 of 663173\n",
      "Review 115000 of 663173\n",
      "Review 116000 of 663173\n",
      "Review 117000 of 663173\n",
      "Review 118000 of 663173\n",
      "Review 119000 of 663173\n",
      "Review 120000 of 663173\n",
      "Review 121000 of 663173\n",
      "Review 122000 of 663173\n",
      "Review 123000 of 663173\n",
      "Review 124000 of 663173\n",
      "Review 125000 of 663173\n",
      "Review 126000 of 663173\n",
      "Review 127000 of 663173\n",
      "Review 128000 of 663173\n",
      "Review 129000 of 663173\n",
      "Review 130000 of 663173\n",
      "Review 131000 of 663173\n",
      "Review 132000 of 663173\n",
      "Review 133000 of 663173\n",
      "Review 134000 of 663173\n",
      "Review 135000 of 663173\n",
      "Review 136000 of 663173\n",
      "Review 137000 of 663173\n",
      "Review 138000 of 663173\n",
      "Review 139000 of 663173\n",
      "Review 140000 of 663173\n",
      "Review 141000 of 663173\n",
      "Review 142000 of 663173\n",
      "Review 143000 of 663173\n",
      "Review 144000 of 663173\n",
      "Review 145000 of 663173\n",
      "Review 146000 of 663173\n",
      "Review 147000 of 663173\n",
      "Review 148000 of 663173\n",
      "Review 149000 of 663173\n",
      "Review 150000 of 663173\n",
      "Review 151000 of 663173\n",
      "Review 152000 of 663173\n",
      "Review 153000 of 663173\n",
      "Review 154000 of 663173\n",
      "Review 155000 of 663173\n",
      "Review 156000 of 663173\n",
      "Review 157000 of 663173\n",
      "Review 158000 of 663173\n",
      "Review 159000 of 663173\n",
      "Review 160000 of 663173\n",
      "Review 161000 of 663173\n",
      "Review 162000 of 663173\n",
      "Review 163000 of 663173\n",
      "Review 164000 of 663173\n",
      "Review 165000 of 663173\n",
      "Review 166000 of 663173\n",
      "Review 167000 of 663173\n",
      "Review 168000 of 663173\n",
      "Review 169000 of 663173\n",
      "Review 170000 of 663173\n",
      "Review 171000 of 663173\n",
      "Review 172000 of 663173\n",
      "Review 173000 of 663173\n",
      "Review 174000 of 663173\n",
      "Review 175000 of 663173\n",
      "Review 176000 of 663173\n",
      "Review 177000 of 663173\n",
      "Review 178000 of 663173\n",
      "Review 179000 of 663173\n",
      "Review 180000 of 663173\n",
      "Review 181000 of 663173\n",
      "Review 182000 of 663173\n",
      "Review 183000 of 663173\n",
      "Review 184000 of 663173\n",
      "Review 185000 of 663173\n",
      "Review 186000 of 663173\n",
      "Review 187000 of 663173\n",
      "Review 188000 of 663173\n",
      "Review 189000 of 663173\n",
      "Review 190000 of 663173\n",
      "Review 191000 of 663173\n",
      "Review 192000 of 663173\n",
      "Review 193000 of 663173\n",
      "Review 194000 of 663173\n",
      "Review 195000 of 663173\n",
      "Review 196000 of 663173\n",
      "Review 197000 of 663173\n",
      "Review 198000 of 663173\n",
      "Review 199000 of 663173\n",
      "Review 200000 of 663173\n",
      "Review 201000 of 663173\n",
      "Review 202000 of 663173\n",
      "Review 203000 of 663173\n",
      "Review 204000 of 663173\n",
      "Review 205000 of 663173\n",
      "Review 206000 of 663173\n",
      "Review 207000 of 663173\n",
      "Review 208000 of 663173\n",
      "Review 209000 of 663173\n",
      "Review 210000 of 663173\n",
      "Review 211000 of 663173\n",
      "Review 212000 of 663173\n",
      "Review 213000 of 663173\n",
      "Review 214000 of 663173\n",
      "Review 215000 of 663173\n",
      "Review 216000 of 663173\n",
      "Review 217000 of 663173\n",
      "Review 218000 of 663173\n",
      "Review 219000 of 663173\n",
      "Review 220000 of 663173\n",
      "Review 221000 of 663173\n",
      "Review 222000 of 663173\n",
      "Review 223000 of 663173\n",
      "Review 224000 of 663173\n",
      "Review 225000 of 663173\n",
      "Review 226000 of 663173\n",
      "Review 227000 of 663173\n",
      "Review 228000 of 663173\n",
      "Review 229000 of 663173\n",
      "Review 230000 of 663173\n",
      "Review 231000 of 663173\n",
      "Review 232000 of 663173\n",
      "Review 233000 of 663173\n",
      "Review 234000 of 663173\n",
      "Review 235000 of 663173\n",
      "Review 236000 of 663173\n",
      "Review 237000 of 663173\n",
      "Review 238000 of 663173\n",
      "Review 239000 of 663173\n",
      "Review 240000 of 663173\n",
      "Review 241000 of 663173\n",
      "Review 242000 of 663173\n",
      "Review 243000 of 663173\n",
      "Review 244000 of 663173\n",
      "Review 245000 of 663173\n",
      "Review 246000 of 663173\n",
      "Review 247000 of 663173\n",
      "Review 248000 of 663173\n",
      "Review 249000 of 663173\n",
      "Review 250000 of 663173\n",
      "Review 251000 of 663173\n",
      "Review 252000 of 663173\n",
      "Review 253000 of 663173\n",
      "Review 254000 of 663173\n",
      "Review 255000 of 663173\n",
      "Review 256000 of 663173\n",
      "Review 257000 of 663173\n",
      "Review 258000 of 663173\n",
      "Review 259000 of 663173\n",
      "Review 260000 of 663173\n",
      "Review 261000 of 663173\n",
      "Review 262000 of 663173\n",
      "Review 263000 of 663173\n",
      "Review 264000 of 663173\n",
      "Review 265000 of 663173\n",
      "Review 266000 of 663173\n",
      "Review 267000 of 663173\n",
      "Review 268000 of 663173\n",
      "Review 269000 of 663173\n",
      "Review 270000 of 663173\n",
      "Review 271000 of 663173\n",
      "Review 272000 of 663173\n",
      "Review 273000 of 663173\n",
      "Review 274000 of 663173\n",
      "Review 275000 of 663173\n",
      "Review 276000 of 663173\n",
      "Review 277000 of 663173\n",
      "Review 278000 of 663173\n",
      "Review 279000 of 663173\n",
      "Review 280000 of 663173\n",
      "Review 281000 of 663173\n",
      "Review 282000 of 663173\n",
      "Review 283000 of 663173\n",
      "Review 284000 of 663173\n",
      "Review 285000 of 663173\n",
      "Review 286000 of 663173\n",
      "Review 287000 of 663173\n",
      "Review 288000 of 663173\n",
      "Review 289000 of 663173\n",
      "Review 290000 of 663173\n",
      "Review 291000 of 663173\n",
      "Review 292000 of 663173\n",
      "Review 293000 of 663173\n",
      "Review 294000 of 663173\n",
      "Review 295000 of 663173\n",
      "Review 296000 of 663173\n",
      "Review 297000 of 663173\n",
      "Review 298000 of 663173\n",
      "Review 299000 of 663173\n",
      "Review 300000 of 663173\n",
      "Review 301000 of 663173\n",
      "Review 302000 of 663173\n",
      "Review 303000 of 663173\n",
      "Review 304000 of 663173\n",
      "Review 305000 of 663173\n",
      "Review 306000 of 663173\n",
      "Review 307000 of 663173\n",
      "Review 308000 of 663173\n",
      "Review 309000 of 663173\n",
      "Review 310000 of 663173\n",
      "Review 311000 of 663173\n",
      "Review 312000 of 663173\n",
      "Review 313000 of 663173\n",
      "Review 314000 of 663173\n",
      "Review 315000 of 663173\n",
      "Review 316000 of 663173\n",
      "Review 317000 of 663173\n",
      "Review 318000 of 663173\n",
      "Review 319000 of 663173\n",
      "Review 320000 of 663173\n",
      "Review 321000 of 663173\n",
      "Review 322000 of 663173\n",
      "Review 323000 of 663173\n",
      "Review 324000 of 663173\n",
      "Review 325000 of 663173\n",
      "Review 326000 of 663173\n",
      "Review 327000 of 663173\n",
      "Review 328000 of 663173\n",
      "Review 329000 of 663173\n",
      "Review 330000 of 663173\n",
      "Review 331000 of 663173\n",
      "Review 332000 of 663173\n",
      "Review 333000 of 663173\n",
      "Review 334000 of 663173\n",
      "Review 335000 of 663173\n",
      "Review 336000 of 663173\n",
      "Review 337000 of 663173\n",
      "Review 338000 of 663173\n",
      "Review 339000 of 663173\n",
      "Review 340000 of 663173\n",
      "Review 341000 of 663173\n",
      "Review 342000 of 663173\n",
      "Review 343000 of 663173\n",
      "Review 344000 of 663173\n",
      "Review 345000 of 663173\n",
      "Review 346000 of 663173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 347000 of 663173\n",
      "Review 348000 of 663173\n",
      "Review 349000 of 663173\n",
      "Review 350000 of 663173\n",
      "Review 351000 of 663173\n",
      "Review 352000 of 663173\n",
      "Review 353000 of 663173\n",
      "Review 354000 of 663173\n",
      "Review 355000 of 663173\n",
      "Review 356000 of 663173\n",
      "Review 357000 of 663173\n",
      "Review 358000 of 663173\n",
      "Review 359000 of 663173\n",
      "Review 360000 of 663173\n",
      "Review 361000 of 663173\n",
      "Review 362000 of 663173\n",
      "Review 363000 of 663173\n",
      "Review 364000 of 663173\n",
      "Review 365000 of 663173\n",
      "Review 366000 of 663173\n",
      "Review 367000 of 663173\n",
      "Review 368000 of 663173\n",
      "Review 369000 of 663173\n",
      "Review 370000 of 663173\n",
      "Review 371000 of 663173\n",
      "Review 372000 of 663173\n",
      "Review 373000 of 663173\n",
      "Review 374000 of 663173\n",
      "Review 375000 of 663173\n",
      "Review 376000 of 663173\n",
      "Review 377000 of 663173\n",
      "Review 378000 of 663173\n",
      "Review 379000 of 663173\n",
      "Review 380000 of 663173\n",
      "Review 381000 of 663173\n",
      "Review 382000 of 663173\n",
      "Review 383000 of 663173\n",
      "Review 384000 of 663173\n",
      "Review 385000 of 663173\n",
      "Review 386000 of 663173\n",
      "Review 387000 of 663173\n",
      "Review 388000 of 663173\n",
      "Review 389000 of 663173\n",
      "Review 390000 of 663173\n",
      "Review 391000 of 663173\n",
      "Review 392000 of 663173\n",
      "Review 393000 of 663173\n",
      "Review 394000 of 663173\n",
      "Review 395000 of 663173\n",
      "Review 396000 of 663173\n",
      "Review 397000 of 663173\n",
      "Review 398000 of 663173\n",
      "Review 399000 of 663173\n",
      "Review 400000 of 663173\n",
      "Review 401000 of 663173\n",
      "Review 402000 of 663173\n",
      "Review 403000 of 663173\n",
      "Review 404000 of 663173\n",
      "Review 405000 of 663173\n",
      "Review 406000 of 663173\n",
      "Review 407000 of 663173\n",
      "Review 408000 of 663173\n",
      "Review 409000 of 663173\n",
      "Review 410000 of 663173\n",
      "Review 411000 of 663173\n",
      "Review 412000 of 663173\n",
      "Review 413000 of 663173\n",
      "Review 414000 of 663173\n",
      "Review 415000 of 663173\n",
      "Review 416000 of 663173\n",
      "Review 417000 of 663173\n",
      "Review 418000 of 663173\n",
      "Review 419000 of 663173\n",
      "Review 420000 of 663173\n",
      "Review 421000 of 663173\n",
      "Review 422000 of 663173\n",
      "Review 423000 of 663173\n",
      "Review 424000 of 663173\n",
      "Review 425000 of 663173\n",
      "Review 426000 of 663173\n",
      "Review 427000 of 663173\n",
      "Review 428000 of 663173\n",
      "Review 429000 of 663173\n",
      "Review 430000 of 663173\n",
      "Review 431000 of 663173\n",
      "Review 432000 of 663173\n",
      "Review 433000 of 663173\n",
      "Review 434000 of 663173\n",
      "Review 435000 of 663173\n",
      "Review 436000 of 663173\n",
      "Review 437000 of 663173\n",
      "Review 438000 of 663173\n",
      "Review 439000 of 663173\n",
      "Review 440000 of 663173\n",
      "Review 441000 of 663173\n",
      "Review 442000 of 663173\n",
      "Review 443000 of 663173\n",
      "Review 444000 of 663173\n",
      "Review 445000 of 663173\n",
      "Review 446000 of 663173\n",
      "Review 447000 of 663173\n",
      "Review 448000 of 663173\n",
      "Review 449000 of 663173\n",
      "Review 450000 of 663173\n",
      "Review 451000 of 663173\n",
      "Review 452000 of 663173\n",
      "Review 453000 of 663173\n",
      "Review 454000 of 663173\n",
      "Review 455000 of 663173\n",
      "Review 456000 of 663173\n",
      "Review 457000 of 663173\n",
      "Review 458000 of 663173\n",
      "Review 459000 of 663173\n",
      "Review 460000 of 663173\n",
      "Review 461000 of 663173\n",
      "Review 462000 of 663173\n",
      "Review 463000 of 663173\n",
      "Review 464000 of 663173\n",
      "Review 465000 of 663173\n",
      "Review 466000 of 663173\n",
      "Review 467000 of 663173\n",
      "Review 468000 of 663173\n",
      "Review 469000 of 663173\n",
      "Review 470000 of 663173\n",
      "Review 471000 of 663173\n",
      "Review 472000 of 663173\n",
      "Review 473000 of 663173\n",
      "Review 474000 of 663173\n",
      "Review 475000 of 663173\n",
      "Review 476000 of 663173\n",
      "Review 477000 of 663173\n",
      "Review 478000 of 663173\n",
      "Review 479000 of 663173\n",
      "Review 480000 of 663173\n",
      "Review 481000 of 663173\n",
      "Review 482000 of 663173\n",
      "Review 483000 of 663173\n",
      "Review 484000 of 663173\n",
      "Review 485000 of 663173\n",
      "Review 486000 of 663173\n",
      "Review 487000 of 663173\n",
      "Review 488000 of 663173\n",
      "Review 489000 of 663173\n",
      "Review 490000 of 663173\n",
      "Review 491000 of 663173\n",
      "Review 492000 of 663173\n",
      "Review 493000 of 663173\n",
      "Review 494000 of 663173\n",
      "Review 495000 of 663173\n",
      "Review 496000 of 663173\n",
      "Review 497000 of 663173\n",
      "Review 498000 of 663173\n",
      "Review 499000 of 663173\n",
      "Review 500000 of 663173\n",
      "Review 501000 of 663173\n",
      "Review 502000 of 663173\n",
      "Review 503000 of 663173\n",
      "Review 504000 of 663173\n",
      "Review 505000 of 663173\n",
      "Review 506000 of 663173\n",
      "Review 507000 of 663173\n",
      "Review 508000 of 663173\n",
      "Review 509000 of 663173\n",
      "Review 510000 of 663173\n",
      "Review 511000 of 663173\n",
      "Review 512000 of 663173\n",
      "Review 513000 of 663173\n",
      "Review 514000 of 663173\n",
      "Review 515000 of 663173\n",
      "Review 516000 of 663173\n",
      "Review 517000 of 663173\n",
      "Review 518000 of 663173\n",
      "Review 519000 of 663173\n",
      "Review 520000 of 663173\n",
      "Review 521000 of 663173\n",
      "Review 522000 of 663173\n",
      "Review 523000 of 663173\n",
      "Review 524000 of 663173\n",
      "Review 525000 of 663173\n",
      "Review 526000 of 663173\n",
      "Review 527000 of 663173\n",
      "Review 528000 of 663173\n",
      "Review 529000 of 663173\n",
      "Review 530000 of 663173\n",
      "Review 531000 of 663173\n",
      "Review 532000 of 663173\n",
      "Review 533000 of 663173\n",
      "Review 534000 of 663173\n",
      "Review 535000 of 663173\n",
      "Review 536000 of 663173\n",
      "Review 537000 of 663173\n",
      "Review 538000 of 663173\n",
      "Review 539000 of 663173\n",
      "Review 540000 of 663173\n",
      "Review 541000 of 663173\n",
      "Review 542000 of 663173\n",
      "Review 543000 of 663173\n",
      "Review 544000 of 663173\n",
      "Review 545000 of 663173\n",
      "Review 546000 of 663173\n",
      "Review 547000 of 663173\n",
      "Review 548000 of 663173\n",
      "Review 549000 of 663173\n",
      "Review 550000 of 663173\n",
      "Review 551000 of 663173\n",
      "Review 552000 of 663173\n",
      "Review 553000 of 663173\n",
      "Review 554000 of 663173\n",
      "Review 555000 of 663173\n",
      "Review 556000 of 663173\n",
      "Review 557000 of 663173\n",
      "Review 558000 of 663173\n",
      "Review 559000 of 663173\n",
      "Review 560000 of 663173\n",
      "Review 561000 of 663173\n",
      "Review 562000 of 663173\n",
      "Review 563000 of 663173\n",
      "Review 564000 of 663173\n",
      "Review 565000 of 663173\n",
      "Review 566000 of 663173\n",
      "Review 567000 of 663173\n",
      "Review 568000 of 663173\n",
      "Review 569000 of 663173\n",
      "Review 570000 of 663173\n",
      "Review 571000 of 663173\n",
      "Review 572000 of 663173\n",
      "Review 573000 of 663173\n",
      "Review 574000 of 663173\n",
      "Review 575000 of 663173\n",
      "Review 576000 of 663173\n",
      "Review 577000 of 663173\n",
      "Review 578000 of 663173\n",
      "Review 579000 of 663173\n",
      "Review 580000 of 663173\n",
      "Review 581000 of 663173\n",
      "Review 582000 of 663173\n",
      "Review 583000 of 663173\n",
      "Review 584000 of 663173\n",
      "Review 585000 of 663173\n",
      "Review 586000 of 663173\n",
      "Review 587000 of 663173\n",
      "Review 588000 of 663173\n",
      "Review 589000 of 663173\n",
      "Review 590000 of 663173\n",
      "Review 591000 of 663173\n",
      "Review 592000 of 663173\n",
      "Review 593000 of 663173\n",
      "Review 594000 of 663173\n",
      "Review 595000 of 663173\n",
      "Review 596000 of 663173\n",
      "Review 597000 of 663173\n",
      "Review 598000 of 663173\n",
      "Review 599000 of 663173\n",
      "Review 600000 of 663173\n",
      "Review 601000 of 663173\n",
      "Review 602000 of 663173\n",
      "Review 603000 of 663173\n",
      "Review 604000 of 663173\n",
      "Review 605000 of 663173\n",
      "Review 606000 of 663173\n",
      "Review 607000 of 663173\n",
      "Review 608000 of 663173\n",
      "Review 609000 of 663173\n",
      "Review 610000 of 663173\n",
      "Review 611000 of 663173\n",
      "Review 612000 of 663173\n",
      "Review 613000 of 663173\n",
      "Review 614000 of 663173\n",
      "Review 615000 of 663173\n",
      "Review 616000 of 663173\n",
      "Review 617000 of 663173\n",
      "Review 618000 of 663173\n",
      "Review 619000 of 663173\n",
      "Review 620000 of 663173\n",
      "Review 621000 of 663173\n",
      "Review 622000 of 663173\n",
      "Review 623000 of 663173\n",
      "Review 624000 of 663173\n",
      "Review 625000 of 663173\n",
      "Review 626000 of 663173\n",
      "Review 627000 of 663173\n",
      "Review 628000 of 663173\n",
      "Review 629000 of 663173\n",
      "Review 630000 of 663173\n",
      "Review 631000 of 663173\n",
      "Review 632000 of 663173\n",
      "Review 633000 of 663173\n",
      "Review 634000 of 663173\n",
      "Review 635000 of 663173\n",
      "Review 636000 of 663173\n",
      "Review 637000 of 663173\n",
      "Review 638000 of 663173\n",
      "Review 639000 of 663173\n",
      "Review 640000 of 663173\n",
      "Review 641000 of 663173\n",
      "Review 642000 of 663173\n",
      "Review 643000 of 663173\n",
      "Review 644000 of 663173\n",
      "Review 645000 of 663173\n",
      "Review 646000 of 663173\n",
      "Review 647000 of 663173\n",
      "Review 648000 of 663173\n",
      "Review 649000 of 663173\n",
      "Review 650000 of 663173\n",
      "Review 651000 of 663173\n",
      "Review 652000 of 663173\n",
      "Review 653000 of 663173\n",
      "Review 654000 of 663173\n",
      "Review 655000 of 663173\n",
      "Review 656000 of 663173\n",
      "Review 657000 of 663173\n",
      "Review 658000 of 663173\n",
      "Review 659000 of 663173\n",
      "Review 660000 of 663173\n",
      "Review 661000 of 663173\n",
      "Review 662000 of 663173\n",
      "Review 663000 of 663173\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "print(\"Creating average feature vecs for test reviews\")\n",
    "clean_test_reviews = []\n",
    "for review in test[\"comment_text\"]:\n",
    "    clean_test_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n"
     ]
    }
   ],
   "source": [
    "# Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n",
    "\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit( trainDataVecs, train[\"sentiment\"] )\n",
    "\n",
    "# # Test & extract results \n",
    "predition = forest.predict(np.nan_to_num(testDataVecs))\n",
    "\n",
    "# # Write the test results \n",
    "# output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "# output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )\n",
    "\n",
    "# test_data_features = test_data_features.toarray()\n",
    "# predition = forest.predict(test_data_features)\n",
    "\n",
    "# predition = np.asarray(predition)\n",
    "# test['sentiment'] = predition\n",
    "# test.to_csv('comment_w_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['sentiment'] = predition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('comment_w_sentiment_avg_vector.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Words To Paragraphs, Attempt 2: Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  682.3323299884796 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.wv.syn0\n",
    "num_clusters = word_vectors.shape[0] // 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Time taken for K Means clustering: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.wv.index2word, idx ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "['lucas', 'ken', 'stanley', 'cameron', 'burton', 'sidney', 'leo', 'cinematographer', 'directs', 'composer', 'olivier', 'samuel', 'hal', 'branagh', 'mann', 'kenneth', 'newman', 'lester', 'lang', 'otto']\n",
      "\n",
      "Cluster 1\n",
      "['useless', 'worthless', 'unwatchable']\n",
      "\n",
      "Cluster 2\n",
      "['bambi', 'prequel', 'ringu', 'vastly', 'highlander', 'hellraiser', 'bakshi']\n",
      "\n",
      "Cluster 3\n",
      "['polish', 'similarly', 'les', 'polanski', 'bunuel', 'crumb', 'nikita', 'influences', 'ki', 'biopic', 'filmography', 'di', 'kazan', 'miyazaki', 'quintessential', 'browning', 'zhang', 'chabrol', 'akira', 'stylistic', 'des', 'besson', 'auteur', 'godard', 'braveheart', 'scorcese', 'antonioni', 'gilliam', 'renowned', 'canon', 'fran', 'boorman', 'opus', 'araki', 'shawshank', 'solondz', 'werner', 'herzog', 'kitano', 'visconti', 'tod', 'fassbinder', 'bu', 'realist', 'europa', 'mulholland', 'ferrara', 'lenzi', 'vertigo', 'truffaut', 'angelopoulos', 'almodovar', 'ozon', 'rohmer', 'depalma', 'loach', 'gregg', 'duk', 'goldsworthy', 'pasolini', 'pantheon', 'satyricon', 'takeshi', 'seminal', 'jeunet', 'audiard', 'uel', 'alejandro', 'hark', 'greenaway', 'rollin', 'je', 'eraserhead', 'ingmar', 'yimou', 'deodato', 'surrealist', 'tarkovsky', 'nakata', 'oeuvre', 'umberto', 'jodorowsky', 'sica', 'sade', 'sukiyaki', 'panahi', 'ois', 'saura']\n",
      "\n",
      "Cluster 4\n",
      "['holiday', 'eve', 'reunion', 'breakfast', 'bachelor', 'valentine', 'snoopy', 'attending', 'prom', 'sorority', 'ceremony', 'woodstock', 'reunite', 'thanksgiving', 'easter', 'slumber', 'addams']\n",
      "\n",
      "Cluster 5\n",
      "['highest', 'lowest', 'rates', 'deserving', 'constraints', 'denominator']\n",
      "\n",
      "Cluster 6\n",
      "['warn']\n",
      "\n",
      "Cluster 7\n",
      "['initially', 'spell', 'suspicion']\n",
      "\n",
      "Cluster 8\n",
      "['performing', 'discussing', 'studying', 'feeding']\n",
      "\n",
      "Cluster 9\n",
      "['navy', 'germans', 'troops']\n"
     ]
    }
   ],
   "source": [
    "# For the first 10 clusters\n",
    "for cluster in range(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print (\"\\nCluster %d\" % cluster)\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in range(0,len(word_centroid_map.values())):\n",
    "        if( list(word_centroid_map.values())[i] == cluster ):\n",
    "            words.append(list(word_centroid_map.keys())[i])\n",
    "    print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros( (train[\"sentiment\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "test_centroids = np.zeros(( test[\"sentiment\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
