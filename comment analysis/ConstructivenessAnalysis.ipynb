{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, col, concat_ws, collect_list, lit, log\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ConstructivenessAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "construct = '/Users/ting/Documents/CMPT733/Project/SOCC/annotated/constructiveness/SFU_constructiveness_toxicity_corpus.csv'\n",
    "df = spark.read.load(construct,\n",
    "                     format='com.databricks.spark.csv', \n",
    "                     header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = df.select('article_id','comment_text', 'is_constructive','is_constructive:confidence','toxicity_level','toxicity_level:confidence',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "expert_df = '/Users/ting/Documents/CMPT733/Project/sentimentAnalysis/ydata-ynacc-v1_0/ydata-ynacc-v1_0_expert_annotations.tsv'\n",
    "expert_df = pd.read_csv(expert_df,  sep='\\t')\n",
    "expert_df = expert_df[['sdid','text','constructiveclass','sentiment','persuasiveness']].dropna()\n",
    "print(expert_df.shape)\n",
    "expert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_df['constructiveclass']  = expert_df['constructiveclass'].astype('category').cat.rename_categories([1,0]) #[Constructive, Not constructive]\n",
    "expert_df['sentiment']  = expert_df['sentiment'].astype('category').cat.rename_categories([-1,0, 2, 1]) #[mixed, negative, neutral, positive]\n",
    "expert_df['persuasiveness']  = expert_df['persuasiveness'].astype('category').cat.rename_categories([0,1])#[Not persuasive, Persuasive]\n",
    "\n",
    "expert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expert_df.to_csv('label_construct_sentiment_persuasive_train.csv')\n",
    "# construct_train = \"label_construct_sentiment_persuasive_train.csv\"\n",
    "\n",
    "# df = spark.read.load(construct_train,\n",
    "#                      format='com.databricks.spark.csv', \n",
    "#                      header='true', \n",
    "#                      inferSchema='true')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=True ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "        \n",
    "#     words = [p_stemmer.stem(w) for w in words]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "#     return(words)\n",
    "    if len(words) == 0:\n",
    "        words = ['NULL']\n",
    "    return( \" \".join(words ))\n",
    "\n",
    "udf_review = udf(lambda w: review_to_wordlist(w), StringType())\n",
    "clean_df = df.select('sdid', udf_review(df.text).alias('cleaned_text'),'constructiveclass') \n",
    "clean_df.coalesce(1).write.csv('cleaned_label_construct_sentiment_persuasive_train', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean_data = '/Users/ting/Documents/CMPT733/Project/sentimentAnalysis/cleaned_label_construct_sentiment_persuasive_train/part-00000-03d520ca-658f-4b9e-a783-cc39627d591d-c000.csv'\n",
    "# clean_df = pd.read_csv(clean_data)\n",
    "# clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sdid</th>\n",
       "      <th>text</th>\n",
       "      <th>constructiveclass</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>persuasiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>53971</td>\n",
       "      <td>These things happen , Every job has its dangers.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53971</td>\n",
       "      <td>Sad to hear such a bad thing. Very dangerous j...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>53971</td>\n",
       "      <td>Yes..because too many houses in EU look like t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>135929</td>\n",
       "      <td>I am frankly quite SICK of the phrase \"shoved ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>135929</td>\n",
       "      <td>Ya, I always wonder why the conservatives are ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    sdid                                               text  \\\n",
       "0           0   53971   These things happen , Every job has its dangers.   \n",
       "1           1   53971  Sad to hear such a bad thing. Very dangerous j...   \n",
       "2           2   53971  Yes..because too many houses in EU look like t...   \n",
       "3           3  135929  I am frankly quite SICK of the phrase \"shoved ...   \n",
       "4           4  135929  Ya, I always wonder why the conservatives are ...   \n",
       "\n",
       "   constructiveclass  sentiment  persuasiveness  \n",
       "0                  1          0               0  \n",
       "1                  1         -1               0  \n",
       "2                  1          2               0  \n",
       "3                  0          0               1  \n",
       "4                  0          2               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "construct_train = \"label_construct_sentiment_persuasive_train.csv\"\n",
    "construct_train= pd.read_csv(construct_train)\n",
    "construct_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ting/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "num_reviews = construct_train[\"text\"].size\n",
    "\n",
    "clean_train_reviews = []\n",
    "\n",
    "for i in range( 0, num_reviews ):\n",
    "    clean_train_reviews.append( review_to_wordlist( construct_train[\"text\"][i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000)\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = forest.fit( train_data_features, construct_train[\"constructiveclass\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 197535: expected 3 fields, saw 25\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10012655</td>\n",
       "      <td>33750cc126314c84b4babae99e97b347</td>\n",
       "      <td>think program needs work probably costly overs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10012655</td>\n",
       "      <td>4ce8f60b0ddd442c8a3ac70c15feb954</td>\n",
       "      <td>offshoring reverse well union busting say good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012655</td>\n",
       "      <td>75900e8bd92c451491729551878a166d</td>\n",
       "      <td>spell exploitation disgusting practice sanctio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10012655</td>\n",
       "      <td>ac49765f024640ae93e0913cdfbb4d48</td>\n",
       "      <td>tfws place economy canadians would leave home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10012655</td>\n",
       "      <td>c5b63fd3000e4306960411384e2999b2</td>\n",
       "      <td>temporary workers get paid tim horton rest com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                        comment_id  \\\n",
       "0    10012655  33750cc126314c84b4babae99e97b347   \n",
       "1    10012655  4ce8f60b0ddd442c8a3ac70c15feb954   \n",
       "2    10012655  75900e8bd92c451491729551878a166d   \n",
       "3    10012655  ac49765f024640ae93e0913cdfbb4d48   \n",
       "4    10012655  c5b63fd3000e4306960411384e2999b2   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  think program needs work probably costly overs...  \n",
       "1  offshoring reverse well union busting say good...  \n",
       "2  spell exploitation disgusting practice sanctio...  \n",
       "3  tfws place economy canadians would leave home ...  \n",
       "4  temporary workers get paid tim horton rest com...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = '/Users/ting/Documents/CMPT733/Project/sentimentAnalysis/cleaned_comment/part-00000-803122b2-81f6-4428-8fc6-41962b3705d0-c000.csv'\n",
    "test = pd.read_csv(test_data,quoting=3,error_bad_lines=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "clean_test_reviews = test[\"cleaned_text\"]\n",
    "test_data_features = vectorizer.transform(clean_test_reviews.values.astype('U'))\n",
    "test_data_features = test_data_features.toarray()\n",
    "predition = forest.predict(test_data_features)\n",
    "\n",
    "predition = np.asarray(predition)\n",
    "test['constructiv'] = predition\n",
    "test.to_csv('comment_w_constructive_tfidfbw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
